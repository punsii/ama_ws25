---
title: "Regression: Explaining and Predicting Life Expectancy (Revised Template)"
format:
  html:
    toc: true
    toc-depth: 3
execute:
  warning: false
  message: false
---

# Regression: Explaining and Predicting Life Expectancy (Revised Template)

## Research questions (template)

This chapter is structured around explicit research questions. We answer each with a focused model, diagnostics, and interpretation.

1. Which predictors have the strongest association with life expectancy, and in which direction?
2. What is the impact of immunization coverage on life expectancy (holding other factors constant)?
3. Does alcohol consumption (and BMI) have a positive or negative association once economic development is controlled for?
4. Which interaction effects are supported and interpretable (e.g., status $\times$ immunization, status $\times$ expenditure, status $\times$ alcohol)?
5. How do outliers / influential observations affect coefficients and conclusions?
6. How well do models generalize to a holdout year (2011)?
7. Can we fit a model on the full panel without violating residual autocorrelation assumptions?
8. Supervised PCA regression and PC interpretation are handled separately in [Regression: Supervised PCA](5_regression_supervised_pca.qmd).

::: {.callout-note}
**Template guidance:** Each section below should answer one of the research questions above. Keep the model scope narrow per section, use `ModelRegistry` and `RegressionResult` diagnostics, and include short interpretation paragraphs.
:::

```{python}
# | label: setup
# | include: false
from typing import TYPE_CHECKING
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display

from ama_tlbx.analysis import FeatureGroup
from ama_tlbx.analysis.model_registry import ModelRegistry
from ama_tlbx.data import LECol, LifeExpectancyDataset
from ama_tlbx.utils.plotting_config import DEFAULT_PLOT_CFG
from ama_tlbx.data.undp_hdr_columns import UNDPHDRColumn as HDRCol
from ama_tlbx.data.undp_hdr_dataset import UNDPHDRDataset

if TYPE_CHECKING:
    from ama_tlbx.analysis.ols_helper import RegressionResult

DEFAULT_PLOT_CFG.apply_global()
np.random.seed(42)

TRAIN_YEAR = 2014
HOLDOUT_YEAR = 2011
STATUS_DUMMY = "status_developed"
```

## Data preparation and splits

We use a 2014 cross-section for training and a 2011 cross-section for holdout evaluation. Transformations are applied consistently via `tf_and_norm` (default per-column transforms) and numeric predictors are z-scored on the pooled (2014 + 2011) sample so that model evaluation uses a consistent scale across years. The target stays in years, so coefficients read as **years of life expectancy per 1 SD increase** in the predictor (status dummy is a 0/1 difference). The binary `status_developed` flag is created by `_status_dummies` (1 = developed, 0 = developing).

<!-- QUESTION: Does it make sense to use adult mortality as predictive feature? -->
```{python}
# | label: data-prep
# | code-fold: true
# Load full panel (updated dataset merged with original expenditures in loader)
panel_ds = LifeExpectancyDataset.from_csv_updated(
    aggregate_by_country=False,
    resolve_nand_pred="carry_forward",
)

# Merge UNDP HDR HDI for the two evaluation years (upper-bound baseline; see RQ1 discussion).
hdr_hdi = (
    UNDPHDRDataset.from_csv(years=[TRAIN_YEAR, HOLDOUT_YEAR])
    .df[[str(HDRCol.ISO3), str(HDRCol.YEAR), str(HDRCol.HDI)]]
    .rename(columns={str(HDRCol.HDI): str(LECol.HDI)})
)

panel_df = (
    panel_ds.with_iso3()
    .assign(year=lambda d: d[LECol.YEAR].dt.year.astype(int))
    .merge(hdr_hdi, on=[HDRCol.ISO3, HDRCol.YEAR], how="left")
)

df_train = (
    LifeExpectancyDataset.from_csv_updated(
        aggregate_by_country=TRAIN_YEAR,
        resolve_nand_pred="carry_forward",
    )
    .merge_undp(hdr_hdi.query("year == @TRAIN_YEAR"))
    .tf_and_norm()
    .set_index("iso3")
    .drop(columns=[LECol.YEAR])
)

df_test = (
    LifeExpectancyDataset.from_csv_updated(
        aggregate_by_country=HOLDOUT_YEAR,
        resolve_nand_pred="carry_forward",
    )
    .merge_undp(hdr_hdi.query("year == @HOLDOUT_YEAR"))
    .tf_and_norm()
    .set_index("iso3")
    .drop(columns=[LECol.YEAR])
)

display(df_train.head().round(2))
```

```{python}
# | label: feature-groups
# | include: true
# | code-fold: false
feature_groups = [
    FeatureGroup(
        name="child_mortality",
        features=[LECol.INFANT_DEATHS, LECol.UNDER_FIVE_DEATHS],
    ),
    FeatureGroup(
        name="child_nutrition",
        features=[LECol.THINNESS_5_9_YEARS, LECol.THINNESS_1_19_YEARS],
    ),
    FeatureGroup(
        name="economic_development",
        features=[LECol.GDP, LECol.PERCENTAGE_EXPENDITURE],
    ),
    FeatureGroup(
        name="immunization",
        features=[LECol.DIPHTHERIA, LECol.HEPATITIS_B, LECol.POLIO],
    ),
]

reduced_columns = [feature for g in feature_groups for feature in g.features]

pca_groups = (
    LifeExpectancyDataset(df=df_train)
    .make_pca_dim_reduction_analyzer(
        feature_groups=feature_groups,
        standardized=True,
        min_var_explained=0.8,
    )
    .fit()
    .result()
)
```

::: {.callout-note collapse="true"}

### Dimensionality reduction via grouped PCA

```{python}
# | label: fig-pca-group-loadings
# | fig-cap: "Grouped PCA loadings for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_loadings().show()
```

```{python}
# | label: fig-pca-group-variance
# | fig-cap: "Explained variance by PCA component for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_variance_summary().show()
```

```{python}
# | label: tbl-pca-group-variance
# | tbl-cap: "Explained variance per group and PC (multi-index)."
pca_groups.explained_variance_table().round(3)
```

The PCA variance summary in @fig-pca-group-variance shows that **child mortality** and **child nutrition** are essentially one-dimensional (PC1 captures >99%), **economic development** requires two PCs to explain >80% of variance, however the second PC explains just 22% of the variance so the first PC captures the main signal. Whether both PCs provide explanatory power will be tested in the subsequent sections. In the **immunization** block, PC1 captures overall vaccination coverage (HepB, diphtheria, polio), while the second and thrid PCs capture residual variations.

<!-- To interpret coefficients that use the PCA-compressed predictors, we inspect the loadings in @fig-pca-group-loadings and @tbl-tbl-pca-group-variance. In the **economic development** block, PC1 is dominated by GDP and health expenditure, so higher `economic_development_PC1` reflects a more affluent / higher-spending profile (up to sign).  Because PCA component signs are arbitrary, we always interpret the *direction* of a PC coefficient jointly with its loadings. -->
:::

```{python}
# | label: fig-corr-map
# | fig-cap: "Correlation heatmap of training data after transformations and PCA compression."
# | code-fold: true
train_index = df_train.index
test_index = df_test.index
df_train = pca_groups.reduced_df.assign(**df_train.drop(columns=reduced_columns))
df_train.index = train_index
holdout_scaled = pca_groups.transform(df_test).assign(
    **df_test.drop(columns=reduced_columns)
)
holdout_scaled.index = test_index

pcs_by_group = {
    gr.group.name: gr.pc_scores.columns.tolist() for gr in pca_groups.group_results
}
econ_pcs = pcs_by_group.get("economic_development", [])
immun_pcs = pcs_by_group.get("immunization", [])

scaled_train_ds = LifeExpectancyDataset(df=df_train)
scaled_train_ds.make_correlation_analyzer().result().plot_heatmap().show()
```

The correlation structure in @fig-corr-map aligns with expectations: adult mortality and HIV/AIDS are strongly negative with life expectancy, while economic development and HDI move positively; alcohol and BMI correlate with development, motivating the conditional alcohol/BMI specification; and the immunization PC correlation must be interpreted via loadings because the sign is arbitrary.

```{python}
# | include: false
def _tf_expr(feature: str | LECol) -> str:
    name = str(feature)
    label = LECol.transform_label(feature)
    if label == "dummy":
        return f"dummy({name})"
    if label == "none":
        return name
    if label == "_log1p_under_coverage":
        return f"log1p(100 - {name})"
    return f"{label}({name})"


def _tf_label(col: str) -> str:
    if col.startswith("status_"):
        return "dummy"
    if "_PC" in col:
        group_name = col.split("_PC", maxsplit=1)[0]
        features = group_features.get(group_name, [])
        if features:
            return f"pca({', '.join(_tf_expr(f) for f in features)})"
        return "pca"
    return _tf_expr(col)


```

:::{.callout-note collapse="true"}

### Feature summary and transformations

To verify the transformations and standardization, we summarize the training features in @tbl-feature-summary, sorted by correlation with life expectancy, along with the applied transformations in @tbl-transforms.

```{python}
# | label: tbl-feature-summary
# | tbl-cap: "Feature summary, transformed and standardized, sorted by correlation with life expectancy."
# | echo: false
summary = df_train.describe().T
target_corr = df_train.corr(numeric_only=True)[LECol.TARGET]

group_features = {g.name: g.features for g in feature_groups}

summary = summary.assign(
    corr_LE=summary.index.map(lambda c: target_corr.get(str(c), np.nan)),
).sort_values("corr_LE", key=lambda s: s.abs(), ascending=False)
transforms = pd.DataFrame(dict(transform=[_tf_label(str(c)) for c in summary.index]))
summary.index = [scaled_train_ds.get_pretty_name(str(c)) for c in summary.index]
transforms.index = summary.index
summary.round(2)
```

```{python}
# | label: tbl-transforms
# | tbl-cap: "Transformations applied to each feature (including PCA inputs)."
# | echo: false
with pd.option_context("display.max_colwidth", None):
    display(transforms)
```

:::

## Baseline: Upper-bound fits through adult mortality and HDI

**RQ1 (signal strength):** establish baseline fit and marginal effects for 1–2 key predictors.


<!-- Model (upper-bound check): `life_expectancy ~ adult_mortality + human_development_index` -->

::: {.callout-note collapse="true"}

### Model: Baseline with adult mortality only

```{python}
# | label: baseline-model-adult-mortality
# | code-fold: true
registry = ModelRegistry(eval_year=HOLDOUT_YEAR)

# Example: adult mortality only
rhs_m1 = str(LECol.ADULT_MORTALITY)
m1 = registry.fit(
    df_train[[LECol.TARGET, LECol.ADULT_MORTALITY]].dropna(),
    name="m1_adult_mortality",
    rhs=rhs_m1,
)

display(m1)
```

Adult mortality is (by construction) tightly linked to life expectancy. In the 2014 cross‑section, a one‑standard‑deviation increase in `adult_mortality` is associated with **-7.70 years** (t‑test p < 0.001; 95% CI **[-8.09, -7.31]**). The model is significant and explains **$R^2 = 0.904$** of the variance. The diagnostics in @fig-baseline-diagnostics show a U‑shape in residuals vs fitted (hinting at mild nonlinearity), a clear widening of residual spread at low fitted values (scale‑location), and tail deviations in the QQ‑plot. This aligns with the tests: **heteroskedasticity** is present, and linearly related to `adult_mortality` (BP p < 0.001).
While Shapiro indicates non-normality (p = 0.008), JB suggests that the kurtosis and skewness are not extreme. This suggests that CIs and t-tests are likely reasonably reliable. Practically, that means OLS standard errors and CIs are likely optimistic, and tail inferences are less reliable even though the central fit is good. \\
The residuals vs `adult_mortality` plot shows a few large positive deviations at high mortality, and the influence plot flags high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **South Africa**). Taken together, this model is best treated as a **strong predictive baseline**, not a causal explanation.

```{python}
# | label: fig-baseline-diagnostics
# | fig-cap: "Baseline residual diagnostics."
_ = m1.plot_residual_diags()
```

:::

:::{.callout-note collapse="true"}
### Model: Baseline with adult mortality + HDI
```{python}
# | label: baseline-model-adult-mortality-hdi
# | code-fold: true
# HDI upper-bound check (HDI embeds life expectancy).
rhs_m1_hdi = " + ".join([str(LECol.ADULT_MORTALITY), str(LECol.HDI)])
m1_hdi = registry.fit(
    df_train[[LECol.TARGET, LECol.ADULT_MORTALITY, LECol.HDI]].dropna(),
    name="m1_adult_mortality_hdi",
    rhs=rhs_m1_hdi,
)
display(m1_hdi)
```

```{python}
# | label: fig-baseline-diagnostics-hdi
# | fig-cap: "Baseline + HDI residual diagnostics."
_ = m1_hdi.plot_residual_diags()
```

Adding HDI yields a substantially tighter fit (**$R^2 = 0.955$**, RMSE = **1.73 years**, $n=165$), and both predictors remain statistically precise. Because the predictors are z-standardized, the coefficients can be read as **years of life expectancy per 1 SD change** in the predictor. Holding HDI constant, a one-standard-deviation increase in adult mortality is associated with **−5.38 years** of life expectancy (95% CI **[−5.81, −4.94]**, $p<0.001$). Holding adult mortality constant, a one-standard-deviation increase in HDI is associated with **+2.95 years** (95% CI **[2.51, 3.38]**, $p<0.001$). In this specification, adult mortality contributes the stronger marginal signal, while HDI still adds a large incremental association.

Substantively, this model is best treated as a **benchmark / upper bound**, not a mechanistic explanation. HDI is a composite index whose construction is closely tied to population health and (in many definitions) directly incorporates life expectancy or closely related quantities. As a result, including HDI risks **target leakage** and can inflate apparent explanatory power. The correct takeaway is therefore limited but useful: *given a mortality proxy and a high-level development/health proxy, little residual variance remains in the cross-section*. This does not justify interpreting HDI as an “independent driver” in the same sense as the domain predictors that follow.

From a numerical stability perspective, the model is well-conditioned (condition number **2.90**, max VIF **2.63**), so the large standard errors typical of severe multicollinearity are not the main issue here. The main caveat is the error structure. The residual diagnostics in Figure @fig-baseline-diagnostics-hdi show clear tail deviations (normality tests reject: JB $p<0.001$, Shapiro $p<0.001$) and persistent heteroscedasticity (Breusch–Pagan $p=0.007$, White $p=0.005$). This means the default “nonrobust” OLS standard errors and confidence intervals can be biased; for confirmatory inference one would prefer heteroscedasticity-robust standard errors (e.g., HC3). For our purposes, we emphasize effect sizes, uncertainty, and sensitivity checks rather than marginal p-values.

Influence diagnostics indicate that a small subset of countries has disproportionate impact on the fitted surface (Cook’s distance flags **10** observations above the $4/n$ heuristic; max leverage **0.139**, max Cook’s **0.395**). The influence plot highlights especially high-leverage cases (e.g., **Lesotho**; and a large negative-residual, influential case such as **Somalia**). These points do not invalidate the model, but they reinforce that the “near-perfect” fit partly relies on a few extreme observations.

In the interpretability-focused models below, we therefore **avoid using HDI**. We also treat `adult_mortality` as a near-tautological benchmark predictor: it provides an informative baseline for predictive performance, but it is too close to the outcome’s definition to serve as the central explanatory variable when the goal is to identify modifiable determinants.
:::

:::{.callout-note collapse="true"}

### Baseline: Socioeconomic predictors

Before testing specific hypotheses about immunization, BMI, or alcohol, we establish a **socio-economic baseline model** that captures the dominant development-related gradient in the data (education, income/expenditure, and development status). This baseline serves two purposes: (i) it provides a realistic reference level of explanatory and predictive performance, and (ii) it reduces **confounding**, i.e., it prevents us from mistaking “rich countries both vaccinate more and live longer” for a direct immunization effect. In the subsequent sections we therefore evaluate each additional block (immunization, lifestyle/nutrition) by its **incremental contribution beyond socio-economics** (changes in AIC/adjusted $R^2$, holdout RMSE) and by whether the added effects remain stable under diagnostics and sensitivity checks.

```{python}
# | label: socioeconomic-baseline-model
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
econ_pc2 = econ_pcs[1] if len(econ_pcs) > 1 else None

base_block = [LECol.SCHOOLING]
if econ_pc1 is not None:
    base_block.append(econ_pc1)

if econ_pc2 is not None:
    base_block.append(econ_pc2)

train_base = df_train[[LECol.TARGET, *base_block]]

base_diag = registry.fit(
    train_base,
    name="m_socioeconomic",
    rhs=" + ".join(str(c) for c in base_block),
)
display(base_diag)
```



display(base_diag)AIC without interaction, with STATUS_DUMMY, no PC2: 987.160
AIC without interaction, with Status_Dummy, with PC2: 967
life_expectancy ~ z(schooling) + economic_development_PC1 + economic_development_PC2 + child_mortality_PC1: aic=844.049
life_expectancy ~ z(schooling) + economic_development_PC1 + child_mortality_PC1: aic=845.5
life_expectancy ~ z(schooling) + economic_development_PC1 + economic_development_PC2: aix=965, r2:0.7
```{python}
# | label: fig-socioeconomic-diagnostics
# | fig-cap: "Socioeconomic baseline model diagnostics."
# | echo: false
_ = base_diag.plot_residual_diags()
```

:::



## Immunization impact

**RQ2:** quantify the effect of immunization coverage (e.g., DTP3, HepB, Polio) controlling for development and mortality burden.

Base model: `life_expectancy ~ status_developed + hiv_aids + economic_development_PC1`
Immunization model: `life_expectancy ~ status_developed + hiv_aids + economic_development_PC1 + immunization_PC1`

```{python}
# | label: immunization-model
# | code-fold: true
immun_pc1 = immun_pcs[0] if immun_pcs else None
if immun_pc1 is None:
    raise ValueError(
        "Immunization PC group is missing; check `feature_groups` in data prep."
    )

immun_cols = [LECol.TARGET, *base_block, immun_pc1]
rhs_immun_reduced = " + ".join(str(c) for c in immun_cols if c != LECol.TARGET)
immun_reduced = registry.fit(
    df_train[immun_cols],
    name="m_immunization_reduced",
    rhs=rhs_immun_reduced,
    refit=True,
)
display(immun_reduced)
```

```{python}
# | label: fig-immunization-diagnostics
# | fig-cap: "Immunization model diagnostics."
immun_reduced.plot_residual_diags()
```

```{python}
# | label: fig-immunization-compare
# | tbl-cap: "Immunization block added vs base model."
registry.compare(sort_by="aic").loc[["m_socioeconomic", "m_immunization_reduced"]]
```

Adding `immunization_PC1` improves fit relative to the base model (**$R^2$: 0.743 $\rightarrow$ 0.792**, RMSE: **4.11 $\rightarrow$ 3.69 years**, @tbl-immunization-compare). The model is jointly significant (F‑test p < 0.001), and `immunization_PC1` is negative and precise (**-1.17 years per 1 SD**, p < 0.001; 95% CI **[-1.55, -0.80]**). Because PCA component signs are arbitrary, we interpret the *direction* of `immunization_PC1` via its loadings in @fig-pca-group-loadings: higher vaccination coverage corresponds to higher life expectancy.

Diagnostics in @fig-immunization-diagnostics show normality is acceptable for the immunization model (JB p = 0.145; Shapiro p = 0.164), so t‑tests/CIs are reasonably interpretable, but heteroskedasticity persists (BP p = 0.002; White p = 0.005), which can bias OLS standard errors and confidence intervals. The influence plot highlights a small set of high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **Nigeria**), so the immunization effect should be interpreted as a **robust association**, not a precise causal magnitude.

## Alcohol and BMI: conditional effects

**RQ3:** test whether alcohol and BMI remain positive once economic development is controlled (and whether signs flip).

Model: `life_expectancy ~ status_developed + total_expenditure + economic_development_PC1 + alcohol + bmi`

```{python}
# | label: alcohol-bmi-model
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
controls = [STATUS_DUMMY, LECol.TOTAL_EXPENDITURE]
if econ_pc1 is not None:
    controls.append(econ_pc1)

health = [LECol.ALCOHOL, LECol.BMI]

model_cols = [LECol.TARGET, *controls, *health]
train_alc = df_train[model_cols].dropna()

rhs_alc = " + ".join(str(c) for c in model_cols if c != LECol.TARGET)
alc_diag = registry.fit(
    train_alc,
    name="m_alcohol_bmi",
    rhs=rhs_alc,
)
display(alc_diag)
```

```{python}
# | label: alcohol-bmi-diagnostics
# | fig-cap: "Alcohol and BMI model diagnostics."
_ = alc_diag.plot_residual_diags()
```

Conditional on development status, total health expenditure, and the economic‑development PC, `bmi` remains positively associated with life expectancy (**+1.93 years per 1 SD**, p < 0.001; 95% CI **[1.00, 2.86]**). In contrast, `alcohol` is small and not statistically different from zero (**-0.33 years per 1 SD**, p = 0.514; 95% CI **[-1.33, 0.67]**). The model is jointly significant (F‑test p < 0.001), but overall fit is comparatively weak (**$R^2 = 0.608$**, RMSE = **5.07 years**). Normality fails (JB p < 0.001; Shapiro p = 0.001) and BP indicates heteroskedasticity (BP p = 0.008), so p‑values and CIs should be treated cautiously.

The influence plot highlights a small set of countries with disproportionate impact on the fit (Cook’s distance flags **11** countries under the 4/n rule), so any alcohol-related conclusion should be framed as **fragile** in cross-sectional OLS unless it remains stable under sensitivity checks.

## Nonlinearity and thresholds

**RQ3 (continued):** test diminishing returns for GDP, health expenditure, and immunization using simple quadratic terms.

Model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + immunization_PC1`

```{python}
# | label: nonlinearity-models
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
immun_pc1 = immun_pcs[0] if immun_pcs else None
nl_terms = [t for t in (econ_pc1, LECol.TOTAL_EXPENDITURE, immun_pc1) if t is not None]
nl_base = [LECol.HIV_AIDS, STATUS_DUMMY, *nl_terms]
nl_df = df_train[[LECol.TARGET, *nl_base]].dropna()

rhs_linear = " + ".join(str(t) for t in nl_base)
nl_linear = registry.fit(
    nl_df,
    name="m_nonlinear_linear",
    rhs=rhs_linear,
)
display(nl_linear)
```

This parsimonious linear specification explains **$R^2 = 0.798$** of the variance (RMSE = **3.64 years**) and is jointly significant (F‑test p < 0.001). Key effects (years per 1 SD) are: `hiv_aids` **-3.40** (p < 0.001; 95% CI **[-4.00, -2.80]**), `economic_development_PC1` **+2.80** (p < 0.001; 95% CI **[2.24, 3.36]**), `total_expenditure` **+0.67** (p = 0.033; 95% CI **[0.06, 1.29]**), and `immunization_PC1` **-1.13** (p < 0.001; 95% CI **[-1.51, -0.76]**). Normality is acceptable (JB p = 0.119; Shapiro p = 0.111), but heteroskedasticity persists (BP p = 0.002; White p = 0.011), so OLS SEs/CIs may be biased. Cook’s distance flags **12** observations, so we treat this as a **robust baseline association model** rather than precise causal inference.

## Effect modification (interactions)

**RQ4:** test development-status interactions for immunization, expenditure, and alcohol.

Base model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + alcohol + immunization_PC1`
Interaction model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + alcohol + immunization_PC1 + status_developed:alcohol`

```{python}
# | label: interaction-models
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
immun_pc1 = immun_pcs[0] if immun_pcs else None

main_terms = [LECol.HIV_AIDS, STATUS_DUMMY]
if econ_pc1 is not None:
    main_terms.append(econ_pc1)
main_terms.extend([LECol.TOTAL_EXPENDITURE, LECol.ALCOHOL])
if immun_pc1 is not None:
    main_terms.append(immun_pc1)

rhs_main = " + ".join(str(t) for t in main_terms)
train_int = df_train[[LECol.TARGET, *main_terms]].dropna()

int_base = registry.fit(
    train_int,
    name="m_interactions_base",
    rhs=rhs_main,
    refit=True,
)
display(int_base)

rhs_int_reduced = " + ".join([rhs_main, f"{STATUS_DUMMY}:{LECol.ALCOHOL}"])
int_diag = registry.fit(
    train_int,
    name="m_interactions_reduced",
    rhs=rhs_int_reduced,
    refit=True,
)
display(int_diag)
```

```{python}
# | label: interaction-slopes
# | fig-cap: "Interaction plot: predicted alcohol slope by development status."
from ama_tlbx.plotting.regression_plots import plot_interaction_effect

plt.figure(figsize=(8, 4))
plot_interaction_effect(
    int_diag,
    x=str(LECol.ALCOHOL),
    by=STATUS_DUMMY,
    df=train_int,
)
plt.show()
```

```{python}
# | label: interaction-diagnostics
# | fig-cap: "Interaction model diagnostics."
int_diag.plot_residual_diags()
```

```{python}
# | label: tbl-interaction-vif
# | tbl-cap: "VIF table for the interaction model (collinearity check)."
display(int_diag.vif)
```

The interaction plot shows **opposing alcohol slopes** by development status: a mildly positive slope for developing countries and a negative slope for developed countries. In the interaction model, `alcohol` is positive (**+0.87 years per 1 SD**, p = 0.026; 95% CI **[0.11, 1.64]**) while the interaction term is negative (**-3.71**, p = 0.055; 95% CI **[-7.49, 0.08]**), implying a developed‑country slope of roughly **-2.84 years per 1 SD**. The model is jointly significant (F‑test p < 0.001), but normality fails (JB p = 0.002; Shapiro p = 0.006) and BP indicates heteroskedasticity (BP p = 0.002), so p‑values/CIs should be treated cautiously. Collinearity is substantial (max VIF **12.6**, @tbl-interaction-vif), which inflates SEs and weakens stability. We therefore treat effect modification as **exploratory** and do not use this interaction specification as the chapter’s final interpretable model.

## Influence and outliers

**RQ5:** evaluate sensitivity to influential countries using Cook’s distance and leverage.

Trimmed refit: same formula as the nonlinearity model, estimated after excluding observations with Cook’s distance > 4/n.

```{python}
# | label: influence-sensitivity
# | code-fold: true
final_diag = nl_linear
cooks = final_diag.assumptions.cooks_distance
threshold = 4 / len(cooks)
keep = cooks <= threshold

sens_diag = registry.fit(
    nl_df.loc[keep],
    name="m_nonlinear_linear_trimmed",
    rhs=rhs_linear,
    refit=True,
)
display(sens_diag)
```

Trimming a small set of influential observations (Cook’s distance > 4/n) is a simple sensitivity check. In our data this removes **13 countries** (179 $\rightarrow$ 166 observations). The trimmed model remains jointly significant (F‑test p < 0.001) with stable key effects (`hiv_aids` **-3.59** years; 95% CI **[-4.21, -2.97]**, `total_expenditure` **+1.21** years; 95% CI **[0.64, 1.77]**, `immunization_PC1` **-1.00** years; 95% CI **[-1.35, -0.66]**). Normality is acceptable (JB p = 0.307; Shapiro p = 0.129), but BP still flags heteroskedasticity (BP p = 0.012), so CIs may still be conservative. The largest absolute coefficient change is about **0.86 years** (for `status_developed`), and holdout RMSE changes only marginally (**4.01 $\rightarrow$ 4.02 years**). The influence plots suggest outliers concentrated in a few high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **South Africa**, **Nigeria**), but the main coefficient signs remain stable, supporting the qualitative conclusions of the baseline model.

## Generalization and holdout performance

**RQ6:** evaluate predictive performance on 2011.

```{python}
# | label: holdout-eval
# | code-fold: true
eval_map = {
    "m1_adult_mortality": holdout_scaled,
    "m_socioeconomic": holdout_scaled,
    "m_immunization_reduced": holdout_scaled,
    "m_alcohol_bmi": holdout_scaled,
    "m_nonlinear_linear": holdout_scaled,
}

for name, df_eval in eval_map.items():
    registry.evaluate_on(
        name,
        df_eval,
        label=f"year{HOLDOUT_YEAR}",
    )

compare_tbl = registry.compare(sort_by=f"year{HOLDOUT_YEAR}_rmse")
compare_tbl.loc[list(eval_map.keys())].round(3)
```

On the 2011 holdout year, the `adult_mortality` benchmark yields the lowest RMSE (**2.89 years**), which is expected because it is very close to the definition of life expectancy. Among the interpretability‑focused models, the **nonlinearity** and **immunization** specifications generalize similarly well (RMSE **4.12** vs **4.12** years), while the alcohol/BMI model performs worst (RMSE **5.84** years). The calibration view in @fig-holdout-calibration shows a mild **S‑shape**: the model tends to **underpredict** life expectancy for the lowest predicted values and slightly **overpredict** around the mid‑range, while high‑end predictions are close to the diagonal. This supports using the burden + development + immunization block as a **parsimonious** generalizable model, but also signals some remaining nonlinear structure.

```{python}
# | label: tbl-global-compare
# | tbl-cap: "Global model comparison (train fit + holdout metrics), sorted by holdout RMSE."
holdout_rmse_col = f"year{HOLDOUT_YEAR}_rmse"
compare_tbl.loc[list(eval_map.keys())].sort_values(holdout_rmse_col).round(3)
```

The global comparison in @tbl-global-compare confirms the pattern above: the `adult_mortality` benchmark dominates pure predictive accuracy, while the **nonlinearity** and **immunization** models offer the best interpretability‑performance trade‑off among the multi‑predictor specifications.

```{python}
# | label: holdout-calibration
# | fig-cap: "Observed vs predicted life expectancy on holdout year (best interpretable model)."
candidate_models = [
    "m_immunization_reduced",
    "m_nonlinear_linear",
    "m_alcohol_bmi",
]
best_name = (
    compare_tbl.loc[candidate_models, holdout_rmse_col].dropna().idxmin()
    if candidate_models
    else compare_tbl[holdout_rmse_col].dropna().idxmin()
)

metrics = registry.get(best_name).eval_metrics_by_label[f"year{HOLDOUT_YEAR}"]
plt.figure(figsize=(7, 5))
metrics.plot_calibration(bins=10, bootstrap=300, random_state=42)
plt.show()
```

## Panel regression and autocorrelation

**RQ7:** fit a model on the full panel and evaluate residual autocorrelation (Durbin–Watson). Interpret carefully; panel dependence is expected.

Model: `life_expectancy ~ adult_mortality + hiv_aids + status_developed` (panel)

```{python}
# | label: panel-model
# | code-fold: true
panel_registry = ModelRegistry()
panel_ds = LifeExpectancyDataset.from_csv(
    aggregate_by_country=False,
    resolve_nand_pred="carry_forward",
)

panel_df = panel_ds.tf_and_norm().drop(columns=[LECol.YEAR])
if STATUS_DUMMY not in panel_df.columns and LECol.STATUS in panel_df.columns:
    panel_df = panel_df.assign(**{STATUS_DUMMY: panel_df[LECol.STATUS].astype(int)})

panel_cols = [LECol.TARGET, LECol.ADULT_MORTALITY, LECol.HIV_AIDS, STATUS_DUMMY]
panel_train = panel_df[panel_cols].dropna()

rhs_panel = " + ".join(str(c) for c in panel_cols if c != LECol.TARGET)
panel_diag = panel_registry.fit(
    panel_train,
    name="m_panel",
    rhs=rhs_panel,
)
display(panel_diag)
```

The Durbin–Watson statistic is far below 2 (**DW = 0.48**), indicating strong positive autocorrelation in the panel residuals. The model is jointly significant (F‑test p < 0.001) with sizable effects (e.g., `adult_mortality` **-2.62** years per 1 SD, 95% CI **[-2.92, -2.33]**; `hiv_aids` **-4.43**, CI **[-4.72, -4.14]**; `status_developed` **+6.20**, CI **[5.55, 6.84]**), but autocorrelation and heteroskedasticity (BP p < 0.001; White p < 0.001) violate OLS assumptions. As a result, standard errors and CIs are not reliable in the pooled panel fit (despite $R^2 = 0.709$ and RMSE = 4.71 years). We keep the panel model only as a descriptive sensitivity check and base inference on the cross‑sectional models. A rigorous panel treatment would require country‑clustered or time‑clustered standard errors, or an explicit panel model (fixed effects / random effects / GLS with AR(1) errors), which is outside the scope of this chapter.

## Summary and limitations

Across the 2014 cross-section, we find a clear hierarchy of associations with life expectancy:

- **RQ1 (strongest association):** `adult_mortality` is the single strongest predictor (coef **-7.70 years per 1 SD**, $R^2 = 0.904$), but it is too close to the definition of life expectancy to serve as an interpretable “driver”.
- **RQ2 (immunization impact):** adding `immunization_PC1` improves fit beyond development status, HIV/AIDS burden, and economic development ($R^2$: **0.743 $\rightarrow$ 0.792**; RMSE: **4.11 $\rightarrow$ 3.69** years), with a sizeable immunization component (coef **-1.17 years per 1 SD**, p < 0.001).
- **RQ3 (alcohol/BMI conditional effects):** `bmi` remains positively associated after controls (coef **+1.93**, p < 0.001), while `alcohol` is not robustly different from zero (coef **-0.33**, p = 0.514).
- **RQ4 (effect modification):** the status × alcohol point estimate suggests a sign flip, but the interaction term is only marginal (coef **-3.71**, p = 0.055) once economic development is controlled for; we treat this as exploratory and do not retain interaction terms in the final model.
- **RQ5 (influence/outliers):** trimming **13** high-Cook’s observations changes coefficients modestly (max |Δcoef| $\approx$ 0.86 years) and does not materially change holdout RMSE (4.12 $\rightarrow$ 4.12 years).
- **RQ6 (generalization):** on the 2011 holdout year, the adult‑mortality benchmark generalizes best (RMSE **2.89** years); among interpretable models, nonlinearity and immunization are best (RMSE **4.12** years), while alcohol/BMI is worst (RMSE **5.84** years).
- **RQ7 (panel autocorrelation):** pooled panel OLS shows strong autocorrelation (DW = 0.48), so inference from the panel model is not reliable without a dedicated panel/cluster-robust treatment.

**Limitations.** All findings are descriptive associations in observational data. Several models violate homoscedasticity, and some violate residual normality; we therefore emphasize effect sizes, diagnostics, and sensitivity checks over marginal p-values. Finally, PCA components are linear combinations with arbitrary sign, so interpreting `*_PC1` coefficients requires inspecting loadings (see PCA-related chapters).
