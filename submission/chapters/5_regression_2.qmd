---
title: "Regression: Explaining and Predicting Life Expectancy"
format:
  html:
    toc: true
    toc-depth: 3
execute:
  warning: false
  message: false
  cache: true
---


## Research questions

This chapter is structured around explicit research questions. We answer each with a focused model, diagnostics, and interpretation.

1. Which predictors have the strongest association with life expectancy, and in which direction?
2. How well can we predict life expectancy using **socio-economic predictors only** (without mortality / immunization predictors)?
3. What is the impact of immunization coverage on life expectancy (holding other factors constant)?
4. Does alcohol consumption (and BMI) have a positive or negative association once economic development is controlled for?
5. Which interaction effects are supported and interpretable (e.g., status $\times$ immunization, status $\times$ expenditure, status $\times$ alcohol)?
6. How do outliers / influential observations affect coefficients and conclusions?
7. How well do models generalize to a holdout year (2011)?
8. Can we fit a model on the full panel without violating residual autocorrelation assumptions?
9. Supervised PCA regression and PC interpretation are handled separately in [Regression: Supervised PCA](5_regression_supervised_pca.qmd).

To answer RQ2 (and to reduce confounding in RQ3–RQ5), we include socioeconomic features from the UNDP HDR dataset.

```{python}
# | label: setup
# | include: false
from typing import TYPE_CHECKING
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from IPython.display import display

from ama_tlbx.analysis import FeatureGroup
from ama_tlbx.analysis.model_registry import ModelRegistry
from ama_tlbx.data import LECol, LifeExpectancyDataset
from ama_tlbx.data.utils import (
    DEFAULT_UNDP_SOCIO_COLUMNS,
    merge_undp_hdr_features,
)
from ama_tlbx.utils.plotting_config import DEFAULT_PLOT_CFG
from ama_tlbx.data.undp_hdr_columns import UNDPHDRColumn as HDRCol
from ama_tlbx.data.undp_hdr_dataset import UNDPHDRDataset
from ama_tlbx.analysis import suggest_groups_from_correlation
from ama_tlbx.analysis.ols_helper import EvalMetrics

if TYPE_CHECKING:
    from ama_tlbx.analysis.ols_helper import RegressionResult

DEFAULT_PLOT_CFG.apply_global()
np.random.seed(42)

TRAIN_YEAR = 2014
HOLDOUT_YEAR = 2011
STATUS_DUMMY = "status_developed"


def _rename_hdi(dataset: LifeExpectancyDataset) -> LifeExpectancyDataset:
    df = dataset.df
    if str(LECol.HDI) not in df.columns and str(HDRCol.HDI) in df.columns:
        df = df.rename(columns={str(HDRCol.HDI): str(LECol.HDI)})
    return LifeExpectancyDataset(df=df)
```

```{python}
# | include: false
def _tf_expr(feature: str | LECol) -> str:
    name = str(feature)
    label = LECol.transform_label(feature)
    if label == "dummy":
        return f"dummy({name})"
    if label == "none":
        return name
    if label == "_log1p_under_coverage":
        return f"log1p(100 - {name})"
    return f"{label}({name})"


def _tf_label(col: str) -> str:
    if col.startswith("status_"):
        return "dummy"
    if "_PC" in col:
        group_name = col.split("_PC", maxsplit=1)[0]
        features = group_features.get(group_name, [])
        if features:
            return f"pca({', '.join(_tf_expr(f) for f in features)})"
        return "pca"
    return _tf_expr(col)


def fit_additive(
    registry: ModelRegistry,
    df: pd.DataFrame,
    *,
    name: str,
    terms: list[str | LECol],
    extra_terms: list[str] | None = None,
    target_col: str = LECol.TARGET,
    refit: bool = False,
    cook_distance_threshold: float | None = None,
):
    rhs_terms = [str(t) for t in terms]
    if extra_terms:
        rhs_terms.extend(extra_terms)
    rhs = " + ".join(rhs_terms)
    cols = [target_col, *terms]
    data = df[cols].dropna()
    return registry.fit(
        data,
        name=name,
        rhs=rhs,
        refit=refit,
        cook_distance_threshold=cook_distance_threshold,
    )
```


## Data preparation and splits

We use a 2014 cross-section for training and a 2011 cross-section for holdout evaluation. Transformations are applied consistently via `tf_and_norm` (default per-column transforms) and numeric predictors are z-scored on the pooled (2014 + 2011) sample so that model evaluation uses a consistent scale across years. The target stays in years, so coefficients read as **years of life expectancy per 1 SD increase** in the predictor (status dummy is a 0/1 difference). The binary `status_developed` flag is created by `_status_dummies` (1 = developed, 0 = developing).

<!-- QUESTION: Does it make sense to use adult mortality as predictive feature? -->
```{python}
# | label: data-prep
# | code-fold: false
# Load full panel (updated dataset merged with original expenditures in loader)
panel_ds = LifeExpectancyDataset.from_csv_updated(
    aggregate_by_country=False,
    resolve_nand_pred="carry_forward",
)

undp_hdr = UNDPHDRDataset.from_csv(years=[TRAIN_YEAR, HOLDOUT_YEAR])
undp_columns = [str(HDRCol.HDI), *DEFAULT_UNDP_SOCIO_COLUMNS]


def make_dataset(year: int) -> pd.DataFrame:
    return (
        LifeExpectancyDataset.from_csv_updated(
            aggregate_by_country=year,
            resolve_nand_pred="carry_forward",
        )
        .pipe(
            merge_undp_hdr_features,
            undp_dataset=undp_hdr,
            years=[year],
            columns=undp_columns,
        )
        .pipe(_rename_hdi)
        .tf_and_norm()
        .set_index("iso3")
        .drop(
            columns=[
                LECol.YEAR,
                HDRCol.LFPR_F,
                HDRCol.LFPR_M,
                HDRCol.POP_TOTAL,
                HDRCol.PR_F,
                HDRCol.PR_M,
            ]
        )
        .pipe(lambda df: df[~df.index.duplicated(keep="first")])
    )


# Guard against duplicate ISO3 keys after UNDP merges.
df_train = make_dataset(TRAIN_YEAR)
df_test = make_dataset(HOLDOUT_YEAR)

display(df_train.head().round(2))
```

```{python}
# | label: feature-groups
# | include: true
# | code-fold: false
feature_groups = [
    FeatureGroup(
        name="child_mortality",
        features=[LECol.INFANT_DEATHS, LECol.UNDER_FIVE_DEATHS],
    ),
    FeatureGroup(
        name="child_nutrition",
        features=[LECol.THINNESS_5_9_YEARS, LECol.THINNESS_1_19_YEARS],
    ),
    FeatureGroup(
        name="economic_development",
        features=[LECol.GDP, LECol.PERCENTAGE_EXPENDITURE],
    ),
    FeatureGroup(
        name="immunization",
        features=[LECol.DIPHTHERIA, LECol.HEPATITIS_B, LECol.POLIO],
    ),
]

reduced_columns = [feature for g in feature_groups for feature in g.features]

pca_groups = (
    LifeExpectancyDataset(df=df_train)
    .make_pca_dim_reduction_analyzer(
        feature_groups=feature_groups,
        standardized=True,
        min_var_explained=1.0,
    )
    .fit()
    .result()
)
```

::: {.callout-note collapse="true"}

### Dimensionality reduction via grouped PCA

```{python}
# | label: fig-pca-group-loadings
# | fig-cap: "Grouped PCA loadings for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_loadings().show()
```

```{python}
# | label: fig-pca-group-variance
# | fig-cap: "Explained variance by PCA component for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_variance_summary().show()
```

```{python}
# | label: tbl-pca-group-variance
# | tbl-cap: "Explained variance per group and PC (multi-index)."
pca_groups.explained_variance_table().round(3)
```

The PCA variance summary in @fig-pca-group-variance shows that **child mortality** and **child nutrition** are essentially one-dimensional (PC1 captures >99%), **economic development** requires two PCs to explain >80% of variance, however the second PC explains just 22% of the variance so the first PC captures the main signal. Whether both PCs provide explanatory power will be tested in the subsequent sections. In the **immunization** block, PC1 captures overall vaccination coverage (HepB, diphtheria, polio), while the second and thrid PCs capture residual variations.

<!-- To interpret coefficients that use the PCA-compressed predictors, we inspect the loadings in @fig-pca-group-loadings and @tbl-tbl-pca-group-variance. In the **economic development** block, PC1 is dominated by GDP and health expenditure, so higher `economic_development_PC1` reflects a more affluent / higher-spending profile (up to sign).  Because PCA component signs are arbitrary, we always interpret the *direction* of a PC coefficient jointly with its loadings. -->
:::

```{python}
# | label: fig-corr-map
# | fig-cap: "Correlation heatmap of training data after transformations and PCA compression."
# | code-fold: true
train_index = df_train.index
test_index = df_test.index
df_train = pca_groups.reduced_df.assign(**df_train.drop(columns=reduced_columns))
df_train.index = train_index
holdout_scaled = pca_groups.transform(df_test).assign(
    **df_test.drop(columns=reduced_columns)
)
holdout_scaled.index = test_index

pcs_by_group = {
    gr.group.name: gr.pc_scores.columns.tolist() for gr in pca_groups.group_results
}
econ_pcs = pcs_by_group.get("economic_development", [])
immun_pcs = pcs_by_group.get("immunization", [])

scaled_train_ds = LifeExpectancyDataset(df=df_train)
corr_result = scaled_train_ds.make_correlation_analyzer().result()
corr_result.plot_heatmap().show()
```

The correlation matrix displayed in @fig-corr-map contains various columns from the UNDP HDR dataset that reflect socioeconomic development, that we merged into the life expectancy dataset to allow us to to build a stable socioeconomic baseline model.
The correlation structure in @fig-corr-map aligns with expectations: adult mortality and HIV/AIDS are strongly negative with life expectancy, while economic development and HDI move positively; alcohol and BMI correlate with development, motivating the conditional alcohol/BMI specification; and the immunization PC correlation must be interpreted via loadings because the sign is arbitrary.

```{python}
# | code-fold: true
# | label: tbl-suggest-feature-groups
suggested_groups, summary_df = suggest_groups_from_correlation(
    corr_result.matrix,
    threshold=0.8,
    return_summary=True,
)

summary_pretty = summary_df.assign(
    features=lambda d: d.features.apply(
        lambda s: ", ".join(
            scaled_train_ds.get_pretty_name(f.strip()) for f in s.split(",")
        ),
    ),
).loc[:, ["group", "size", "features", "mean_abs_corr", "min_abs_corr"]]

display(
    summary_pretty.assign(features=lambda d: d.features.str.replace(", ", "<br>"))
    .set_index("group")
    .to_html(escape=False)
)
```

Since our previous correlation analysis chapter did not include the UNDP HDR features, we re-run the group suggestion here. "Group 15" in @tbl-suggest-feature-groups collects various social-development incdicators that the life expectancy dataset alone did not cover. The features are:

- schooling: Mean years of schooling (life expectancy dataset)
- se_f / se_m: Population with at least secondary education (female  / male, %; UNDP HDR)
- ineq_edu: Inequality in education (index; UNDP HDR)
- coef_ineq: Coefficient of inequality (I-HDI) - This feature does not represent the HDI discussed in [HDI Investigation](2_investigate_hdi.qmd).

To allow construction of a stable socioeconomic baseline model, we therefore perform PCA based dimensionality reduction on this group as well.

<!-- TODO: perform PCA-group reduction here on these features and transform both datasets -->

```{python}
# | label: feature-groups-2
# | include: true
# | code-fold: false
feature_groups = [
    FeatureGroup(
        name="social_development",
        features=[
            LECol.SCHOOLING,
            HDRCol.SE_F,
            HDRCol.SE_M,
            HDRCol.INEQ_EDU,
            HDRCol.MYS,
            HDRCol.COEF_INEQ,
        ],
    ),
]

reduced_columns = [feature for g in feature_groups for feature in g.features]

pca_groups = (
    LifeExpectancyDataset(df=df_train)
    .make_pca_dim_reduction_analyzer(
        feature_groups=feature_groups,
        standardized=True,
        min_var_explained=0.8,
    )
    .fit()
    .result()
)
```
::: {.callout-note collapse="true"}

### Dimensionality reduction via grouped PCA 2

```{python}
# | label: fig-pca-group-loadings-2
# | fig-cap: "Grouped PCA loadings for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_loadings().show()
```

```{python}
# | label: fig-pca-group-variance-2
# | fig-cap: "Explained variance by PCA component for the reduced feature blocks (training year 2014)."
pca_groups.plot_group_variance_summary().show()
```

```{python}
# | label: tbl-pca-group-variance-2
# | tbl-cap: "Explained variance per group and PC (multi-index)."
pca_groups.explained_variance_table().round(3)
```
:::

```{python}
# | label: social-development-apply
# | code-fold: true
train_idx_social = df_train.index
holdout_idx_social = holdout_scaled.index

df_train = pca_groups.reduced_df.assign(**df_train.drop(columns=reduced_columns))
df_train.index = train_idx_social

holdout_scaled = pca_groups.transform(holdout_scaled).assign(
    **holdout_scaled.drop(columns=reduced_columns)
)
holdout_scaled.index = holdout_idx_social

social_pcs = pca_groups.group_results[0].pc_scores.columns.tolist()
df_test = holdout_scaled.copy()
```

:::{.callout-note collapse="true"}

### Feature summary and transformations

To verify the transformations and standardization, we summarize the training features in @tbl-feature-summary, sorted by correlation with life expectancy, along with the applied transformations in @tbl-transforms.

For the UNDP HDR–based *social development* block, the grouped PCA loadings in @fig-pca-group-loadings-2 show that `social_development_PC1` is essentially an **education vs inequality** axis: it loads **positively** on schooling/education attainment (`schooling`, `se_f`, `se_m`, `mys`) and **negatively** on inequality measures (`ineq_edu`, `coef_ineq`). Since PC1 already captures ~**89%** of the block variance (@fig-pca-group-variance-2), this group is effectively one-dimensional. In the regressions below, a positive coefficient on `social_development_PC1` therefore means higher life expectancy in countries with more education and lower inequality (up to the arbitrary sign of PCA).

```{python}
# | label: tbl-feature-summary
# | tbl-cap: "Feature summary, transformed and standardized, sorted by correlation with life expectancy."
# | echo: false
summary = df_train.describe().T
target_corr = df_train.corr(numeric_only=True)[LECol.TARGET]

group_features = {g.name: g.features for g in feature_groups}

summary = summary.assign(
    corr_LE=summary.index.map(lambda c: target_corr.get(str(c), np.nan)),
).sort_values("corr_LE", key=lambda s: s.abs(), ascending=False)
transforms = pd.DataFrame(dict(transform=[_tf_label(str(c)) for c in summary.index]))
summary.index = [scaled_train_ds.get_pretty_name(str(c)) for c in summary.index]
transforms.index = summary.index
summary.round(2)
```

```{python}
# | label: tbl-transforms
# | tbl-cap: "Transformations applied to each feature (including PCA inputs)."
# | echo: false
with pd.option_context("display.max_colwidth", None):
    display(transforms)
```

:::

## Baseline: Upper-bound fits through adult mortality and HDI

**RQ1 (signal strength):** establish baseline fit and marginal effects for 1–2 key predictors.


<!-- Model (upper-bound check): `life_expectancy ~ adult_mortality + human_development_index` -->

::: {.callout-note collapse="true"}

### Model: Baseline with adult mortality only

```{python}
# | label: baseline-model-adult-mortality
# | code-fold: true
registry = ModelRegistry(eval_year=HOLDOUT_YEAR)

# Example: adult mortality only
m1 = fit_additive(
    registry,
    df_train,
    name="m1_adult_mortality",
    terms=[LECol.ADULT_MORTALITY],
)

display(m1)
```

Adult mortality is (by construction) tightly linked to life expectancy. In the 2014 cross‑section, a one‑standard‑deviation increase in `adult_mortality` is associated with **-7.70 years** (t‑test p < 0.001; 95% CI **[-8.09, -7.31]**). The model is significant and explains **$R^2 = 0.904$** of the variance. The diagnostics in @fig-baseline-diagnostics show a U‑shape in residuals vs fitted (hinting at mild nonlinearity), a clear widening of residual spread at low fitted values (scale‑location), and tail deviations in the QQ‑plot. This aligns with the tests: **heteroskedasticity** is present, and linearly related to `adult_mortality` (BP p < 0.001).
While Shapiro indicates non-normality (p = 0.008), JB suggests that the kurtosis and skewness are not extreme. This suggests that CIs and t-tests are likely reasonably reliable. Practically, that means OLS standard errors and CIs are likely optimistic, and tail inferences are less reliable even though the central fit is good. \\
The residuals vs `adult_mortality` plot shows a few large positive deviations at high mortality, and the influence plot flags high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **South Africa**). Taken together, this model is best treated as a **strong predictive baseline**, not a causal explanation.

```{python}
# | label: fig-baseline-diagnostics
# | fig-cap: "Baseline residual diagnostics."
_ = m1.plot_residual_diags()
```

:::

:::{.callout-note collapse="true"}
### Model: Baseline with adult mortality + HDI
```{python}
# | label: baseline-model-adult-mortality-hdi
# | code-fold: true
# HDI upper-bound check (HDI embeds life expectancy).
m1_hdi = fit_additive(
    registry,
    df_train,
    name="m1_adult_mortality_hdi",
    terms=[LECol.ADULT_MORTALITY, LECol.HDI],
)
display(m1_hdi)
```

```{python}
# | label: fig-baseline-diagnostics-hdi
# | fig-cap: "Baseline + HDI residual diagnostics."
_ = m1_hdi.plot_residual_diags()
```

Adding HDI yields a substantially tighter fit (**$R^2 = 0.955$**, RMSE = **1.73 years**, $n=165$), and both predictors remain statistically precise. Because the predictors are z-standardized, the coefficients can be read as **years of life expectancy per 1 SD change** in the predictor. Holding HDI constant, a one-standard-deviation increase in adult mortality is associated with **−5.38 years** of life expectancy (95% CI **[−5.81, −4.94]**, $p<0.001$). Holding adult mortality constant, a one-standard-deviation increase in HDI is associated with **+2.95 years** (95% CI **[2.51, 3.38]**, $p<0.001$). In this specification, adult mortality contributes the stronger marginal signal, while HDI still adds a large incremental association.

Substantively, this model is best treated as a **benchmark / upper bound**, not a mechanistic explanation. HDI is a composite index whose construction is closely tied to population health and (in many definitions) directly incorporates life expectancy or closely related quantities. As a result, including HDI risks **target leakage** and can inflate apparent explanatory power. The correct takeaway is therefore limited but useful: *given a mortality proxy and a high-level development/health proxy, little residual variance remains in the cross-section*. This does not justify interpreting HDI as an “independent driver” in the same sense as the domain predictors that follow.

From a numerical stability perspective, the model is well-conditioned (condition number **2.90**, max VIF **2.63**), so the large standard errors typical of severe multicollinearity are not the main issue here. The main caveat is the error structure. The residual diagnostics in Figure @fig-baseline-diagnostics-hdi show clear tail deviations (normality tests reject: JB $p<0.001$, Shapiro $p<0.001$) and persistent heteroscedasticity (Breusch–Pagan $p=0.007$, White $p=0.005$). This means the default “nonrobust” OLS standard errors and confidence intervals can be biased; for confirmatory inference one would prefer heteroscedasticity-robust standard errors (e.g., HC3). For our purposes, we emphasize effect sizes, uncertainty, and sensitivity checks rather than marginal p-values.

Influence diagnostics indicate that a small subset of countries has disproportionate impact on the fitted surface (Cook’s distance flags **10** observations above the $4/n$ heuristic; max leverage **0.139**, max Cook’s **0.395**). The influence plot highlights especially high-leverage cases (e.g., **Lesotho**; and a large negative-residual, influential case such as **Somalia**). These points do not invalidate the model, but they reinforce that the “near-perfect” fit partly relies on a few extreme observations.

In the interpretability-focused models below, we therefore **avoid using HDI**. We also treat `adult_mortality` as a near-tautological benchmark predictor: it provides an informative baseline for predictive performance, but it is too close to the outcome’s definition to serve as the central explanatory variable when the goal is to identify modifiable determinants.
:::

```{python}
# | label: tbl-baseline-compare
# | tbl-cap: "Baseline models compared (sorted by AIC)."
registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m1_adult_mortality", "m1_adult_mortality_hdi"]]
```

<!-- TODO: provide a brief flow-text overview of what's being done in undp-socio-pca -->
```{python}
# | label: undp-socio-pca
# | code-fold: true
# Build a UNDP socioeconomic PCA block to stabilize the baseline model.
undp_candidates = [
    HDRCol.GNI_PC,
    HDRCol.EYS,
    HDRCol.GDI,
    HDRCol.GII,
    HDRCol.INEQ_INC,
    HDRCol.CO2_PROD,
    HDRCol.MMR,
    HDRCol.ABR,
]

undp_features = []
for col in undp_candidates:
    name = str(col)
    if name in df_train.columns:
        undp_features.append(name)

undp_features = list(dict.fromkeys(undp_features))

if undp_features:
    undp_group = FeatureGroup(name="undp_socio", features=undp_features)
    undp_pca = (
        LifeExpectancyDataset(df=df_train)
        .make_pca_dim_reduction_analyzer(
            feature_groups=[undp_group],
            standardized=True,
            min_var_explained=0.8,
        )
        .fit()
        .result()
    )
    df_train = undp_pca.reduced_df.assign(**df_train.drop(columns=undp_features))
    holdout_scaled = undp_pca.transform(holdout_scaled).assign(
        **holdout_scaled.drop(columns=undp_features)
    )
    undp_pcs = undp_pca.group_results[0].pc_scores.columns.tolist()
else:
    undp_pcs = []
```



## Baseline: Socioeconomic predictors

**RQ2 (socioeconomic-only prediction):** Before testing specific hypotheses about immunization, BMI, or alcohol, we ask how well life expectancy can be explained and predicted using **socioeconomic predictors only** (education, income/expenditure, and development status), excluding mortality and immunization variables. This baseline serves two purposes: (i) it provides a realistic reference level of explanatory and predictive performance, and (ii) it reduces **confounding**, i.e., it prevents us from mistaking “rich countries both vaccinate more and live longer” for a direct immunization effect. In the subsequent sections we therefore evaluate each additional block (immunization, lifestyle/nutrition) by its **incremental contribution beyond socio-economics** (changes in AIC/adjusted $R^2$, holdout RMSE) and by whether the added effects remain stable under diagnostics and sensitivity checks.

```{python}
# | label: socioeconomic-baseline-model-prep
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
econ_pc2 = econ_pcs[1] if len(econ_pcs) > 1 else None
undp_pc1 = undp_pcs[0] if undp_pcs else None
social_le_undp_pc1 = social_pcs[0] if social_pcs else None

if econ_pc1 is None or econ_pc2 is None:
    raise ValueError("Economic development PCs missing; check `feature_groups`.")
if undp_pc1 is None:
    raise ValueError("UNDP socio PC1 missing; check UNDP merge/PCA block.")
if social_le_undp_pc1 is None:
    raise ValueError("Social development PC1 missing; check PCA block above.")

socio_econ_names = []
```

:::{.callout-note collapse="true"}

### M1: LE ~ econ PCs
```{python}
# | label: socioeconomic-baseline-model-1
# | code-fold: true
# (1) econ PCs only
socio_1 = fit_additive(
    registry,
    df_train,
    name="m_socio_eco_pcs",
    terms=[econ_pc1, econ_pc2],
)
socio_econ_names.append("m_socio_eco_pcs")
display(socio_1)

```
:::

:::{.callout-note collapse="true"}
### M2: LE ~ status + econ PCs + UNDP econ PC1
```{python}
# | label: socioeconomic-baseline-model-2
# | code-fold: true
# (2) add status + UNDP socio PC1
socio_2 = fit_additive(
    registry,
    df_train,
    name="m_socio_eco_undp",
    terms=[STATUS_DUMMY, econ_pc1, econ_pc2, undp_pc1],
)
socio_econ_names.append("m_socio_eco_undp")
display(socio_2)
```
:::

:::{.callout-note collapse="true"}
### M3: LE ~ status + econ PCs + UNDP econ PC1 ^ 2
```{python}
# | label: socioeconomic-baseline-model-3
# | code-fold: true
# (3) status + econ PC1 + quadratic UNDP PC1
socio_3 = fit_additive(
    registry,
    df_train,
    name="m_socio_eco_undp_quad",
    terms=[STATUS_DUMMY, econ_pc1, undp_pc1],
    extra_terms=[f"I({undp_pc1} ** 2)"],
)
socio_econ_names.append("m_socio_eco_undp_quad")
display(socio_3)
```
:::

:::{.callout-note collapse="true"}
### M4: LE ~ status + econ PC1 + UNDP econ PC1 ^ 2 + social PC1
```{python}
# | label: socioeconomic-baseline-model-4
# | code-fold: true
# (4) status + econ PCs + social development PC1
socio_4 = fit_additive(
    registry,
    df_train,
    name="m_socio_eco_social",
    terms=[STATUS_DUMMY, econ_pc1, social_le_undp_pc1, undp_pc1],
    extra_terms=[f"I({undp_pc1} ** 2)"],
)
socio_econ_names.append("m_socio_eco_social")
display(socio_4)
```

While the newly added `social_development_PC1` is barely statistically significant (p = 0.045; CI **[-1.002, -0.001]**), it improves the model fit by about 2 points in AIC (900.32 $\rightarrow$ 898.15) and also improves the statistical stability in all diagnostics. This motivates us to trim down influential outliers via Cook's distance ($> 4/n$: **5** countries removed) to see wether this improves the models parsimony and stability further.

```{python}
# | label: socioeconomic-baseline-model-4-cook
# | code-fold: true
# (4b) status + econ PCs + social development PC1, cook's distance trimming
socio_4_cook_initial, socio_4_cook = fit_additive(
    registry,
    df_train,
    name="m_socio_eco_social_cook",
    terms=[STATUS_DUMMY, econ_pc1, social_le_undp_pc1, undp_pc1],
    extra_terms=[f"I({undp_pc1} ** 2)"],
    cook_distance_threshold=4 / len(df_train),
)
registry.remove("m_socio_eco_social_cook_initial")  # remove initial fit with all data
socio_econ_names.append("m_socio_eco_social_cook")
display(socio_4_cook)
```
:::

```{python}
# | label: tbl-socioeconomic-compare
# | tbl-cap: "Socioeconomic baselines compared (sorted by AIC)."
comp_tbl = (
    registry.compare(sort_by="aic")
    .loc[socio_econ_names]
    .drop(columns=["rhs"])[["aic", "rmse", "r2", "adj_r2", "n_obs"]]
    .sort_values("aic")
)
best_socio_econ_name = comp_tbl.index[0]
best_socio_econ = registry.get(best_socio_econ_name).diag
display(comp_tbl)
```

```{python}
# | label: fig-socioeconomic-diagnostics
# | fig-cap: "Socioeconomic baseline model diagnostics."
# | echo: false
_ = best_socio_econ.plot_residual_diags()
plt.show()
```


Model `m_socio_eco_social` adds `social_development_PC1` (education vs inequality; see @fig-pca-group-loadings-2) on top of the two economic PCs. It explains **$R^2 = 0.700$** (RMSE **4.42 years**, $n=166$). Both economic components are strongly positive (`economic_development_PC1` **+3.28 years**, 95% CI **[2.44, 4.12]**; `economic_development_PC2` **+3.22**, CI **[1.82, 4.62]**; both p < 0.001). The social-development axis is also positive (`social_development_PC1` **+0.95**, CI **[0.45, 1.45]**, p < 0.001), consistent with the interpretation that *more education and less inequality* is associated with higher life expectancy even after controlling for economic structure. In contrast, `status_developed` is not statistically distinguishable from zero (**+0.91**, p = 0.419; CI **[-1.31, 3.14]**), suggesting that the continuous socioeconomic PCs already capture most of what the binary label adds.

Diagnostics in @fig-socioeconomic-diagnostics show mild curvature in residuals vs fitted (remaining nonlinearity), and heteroskedasticity consistent with the tests (Breusch–Pagan p = 0.013; White p = 0.049). The QQ-plot shows pronounced tail deviations (JB p < 0.001; Shapiro p < 0.001), so t-tests and confidence intervals should be treated cautiously (especially for tail-sensitive effects). Influence is concentrated in a small set of high-leverage countries (max Cook’s **0.133**, Cook’s > 4/n: **6**), so coefficient magnitudes should be interpreted as descriptive associations rather than precise causal effects.

Compared across baselines (@tbl-socioeconomic-compare), adding `social_development_PC1` improves the pure economic-PC benchmark (AIC **986.7 $\rightarrow$ 974.6**, RMSE **4.64 $\rightarrow$ 4.42**), but it is still dominated by the UNDP socioeconomic PC baseline, especially with the quadratic term (`m_socio_eco_undp_quad`, AIC **894.2**, RMSE **3.47**).

### Holdout evaluation (socioeconomic baselines)

```{python}
# | label: tbl-socioeconomic-eval
# | tbl-cap: "Holdout-year performance (2011) for socioeconomic baselines."
N_BOOTSTRAP = 3000

eval_socio = dict.fromkeys(
    socio_econ_names,
    None,
)
for name in eval_socio.keys():
    eval_socio[name] = registry.evaluate_on(
        name=name,
        df=holdout_scaled,
        label=f"year{HOLDOUT_YEAR}",
    )

eval_tbl = EvalMetrics.collate_to_df(list(eval_socio.values()))
eval_tbl.insert(0, "model", list(eval_socio.keys()))
eval_tbl.set_index("model").sort_values("rmse").round(3)
```

```{python}
# | label: tbl-socioeconomic-eval-ci
# | tbl-cap: "Bootstrap CIs for holdout metrics (best AIC socioeconomic baseline; B=3000)."
eval_socio[best_socio_econ_name].bootstrap_ci(n_bootstrap=N_BOOTSTRAP, random_state=42).set_index(
    "metric"
)
```

```{python}
# | label: fig-socioeconomic-calibration
# | fig-cap: "Holdout calibration (2011) for best AIC socioeconomic baseline with bootstrap 95% CIs."
plt.figure(figsize=(7, 5))
eval_socio[best_socio_econ_name].plot_calibration(
    bins=10,
    bootstrap=N_BOOTSTRAP,
    random_state=42,
)
plt.show()
```



## Immunization impact

**RQ3:** quantify the effect of immunization coverage (e.g., DTP3, HepB, Polio) controlling for development and mortality burden.

Base model: `life_expectancy ~ status_developed + hiv_aids + economic_development_PC1`
Immunization model: `life_expectancy ~ status_developed + hiv_aids + economic_development_PC1 + immunization_PC1`

```{python}
# | label: immunization-model
# | code-fold: true
immun_pc1 = immun_pcs[0] if immun_pcs else None
if immun_pc1 is None:
    raise ValueError(
        "Immunization PC group is missing; check `feature_groups` in data prep."
    )

econ_pc1 = econ_pcs[0] if econ_pcs else None
immun_base_block = [STATUS_DUMMY, LECol.HIV_AIDS]
if econ_pc1 is not None:
    immun_base_block.append(econ_pc1)

base_diag = fit_additive(
    registry,
    df_train,
    name="m_immun_base",
    terms=immun_base_block,
)
display(base_diag)

immun_reduced = fit_additive(
    registry,
    df_train,
    name="m_immunization_reduced",
    terms=[*immun_base_block, immun_pc1],
    refit=True,
)
display(immun_reduced)
```

```{python}
# | label: fig-immunization-diagnostics
# | fig-cap: "Immunization model diagnostics."
immun_reduced.plot_residual_diags()
```

```{python}
# | label: tbl-immunization-compare
# | tbl-cap: "Immunization block added vs base model."
registry.compare(sort_by="aic").loc[["m_immun_base", "m_immunization_reduced"]]
```

Adding `immunization_PC1` improves fit relative to the base model (**$R^2$: 0.743 $\rightarrow$ 0.792**, RMSE: **4.11 $\rightarrow$ 3.69 years**, @tbl-immunization-compare). The model is jointly significant (F‑test p < 0.001), and `immunization_PC1` is negative and precise (**-1.17 years per 1 SD**, p < 0.001; 95% CI **[-1.55, -0.80]**). Because PCA component signs are arbitrary, we interpret the *direction* of `immunization_PC1` via its loadings in @fig-pca-group-loadings: higher vaccination coverage corresponds to higher life expectancy.

Diagnostics in @fig-immunization-diagnostics show normality is acceptable for the immunization model (JB p = 0.145; Shapiro p = 0.164), so t‑tests/CIs are reasonably interpretable, but heteroskedasticity persists (BP p = 0.002; White p = 0.005), which can bias OLS standard errors and confidence intervals. The influence plot highlights a small set of high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **Nigeria**), so the immunization effect should be interpreted as a **robust association**, not a precise causal magnitude.

## Alcohol and BMI: conditional effects

**RQ4:** test whether alcohol and BMI remain positive once economic development is controlled (and whether signs flip).

Model: `life_expectancy ~ status_developed + total_expenditure + economic_development_PC1 + alcohol + bmi`

```{python}
# | label: alcohol-bmi-model
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
controls = [STATUS_DUMMY, LECol.TOTAL_EXPENDITURE]
if econ_pc1 is not None:
    controls.append(econ_pc1)

health = [LECol.ALCOHOL, LECol.BMI]

train_alc = df_train[[LECol.TARGET, *controls, *health]].dropna()
alc_diag = fit_additive(
    registry,
    train_alc,
    name="m_alcohol_bmi",
    terms=[*controls, *health],
)
display(alc_diag)
```

```{python}
# | label: alcohol-bmi-diagnostics
# | fig-cap: "Alcohol and BMI model diagnostics."
_ = alc_diag.plot_residual_diags()
```

```{python}
# | label: tbl-alcohol-bmi-compare
# | tbl-cap: "Alcohol/BMI model compared (sorted by AIC)."
registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m_alcohol_bmi"]]
```

Conditional on development status, total health expenditure, and the economic‑development PC, `bmi` remains positively associated with life expectancy (**+1.93 years per 1 SD**, p < 0.001; 95% CI **[1.00, 2.86]**). In contrast, `alcohol` is small and not statistically different from zero (**-0.33 years per 1 SD**, p = 0.514; 95% CI **[-1.33, 0.67]**). The model is jointly significant (F‑test p < 0.001), but overall fit is comparatively weak (**$R^2 = 0.608$**, RMSE = **5.07 years**). Normality fails (JB p < 0.001; Shapiro p = 0.001) and BP indicates heteroskedasticity (BP p = 0.008), so p‑values and CIs should be treated cautiously.

The influence plot highlights a small set of countries with disproportionate impact on the fit (Cook’s distance flags **11** countries under the 4/n rule), so any alcohol-related conclusion should be framed as **fragile** in cross-sectional OLS unless it remains stable under sensitivity checks.

## Nonlinearity and thresholds

**RQ4 (continued):** test diminishing returns for GDP, health expenditure, and immunization using simple quadratic terms.

Model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + immunization_PC1`

```{python}
# | label: nonlinearity-models
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
immun_pc1 = immun_pcs[0] if immun_pcs else None
nl_terms = [t for t in (econ_pc1, LECol.TOTAL_EXPENDITURE, immun_pc1) if t is not None]
nl_base = [LECol.HIV_AIDS, STATUS_DUMMY, *nl_terms]
nl_df = df_train[[LECol.TARGET, *nl_base]].dropna()

rhs_linear = " + ".join(str(t) for t in nl_base)
nl_linear = fit_additive(
    registry,
    nl_df,
    name="m_nonlinear_linear",
    terms=nl_base,
)
display(nl_linear)
```

This parsimonious linear specification explains **$R^2 = 0.798$** of the variance (RMSE = **3.64 years**) and is jointly significant (F‑test p < 0.001). Key effects (years per 1 SD) are: `hiv_aids` **-3.40** (p < 0.001; 95% CI **[-4.00, -2.80]**), `economic_development_PC1` **+2.80** (p < 0.001; 95% CI **[2.24, 3.36]**), `total_expenditure` **+0.67** (p = 0.033; 95% CI **[0.06, 1.29]**), and `immunization_PC1` **-1.13** (p < 0.001; 95% CI **[-1.51, -0.76]**). Normality is acceptable (JB p = 0.119; Shapiro p = 0.111), but heteroskedasticity persists (BP p = 0.002; White p = 0.011), so OLS SEs/CIs may be biased. Cook’s distance flags **12** observations, so we treat this as a **robust baseline association model** rather than precise causal inference.

```{python}
# | label: tbl-nonlinearity-compare
# | tbl-cap: "Nonlinearity baseline model compared (sorted by AIC)."
registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m_nonlinear_linear"]]
```

## Effect modification (interactions)

**RQ5:** test development-status interactions for immunization, expenditure, and alcohol.

Base model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + alcohol + immunization_PC1`
Interaction model: `life_expectancy ~ hiv_aids + status_developed + economic_development_PC1 + total_expenditure + alcohol + immunization_PC1 + status_developed:alcohol`

```{python}
# | label: interaction-models
# | code-fold: true
econ_pc1 = econ_pcs[0] if econ_pcs else None
immun_pc1 = immun_pcs[0] if immun_pcs else None

main_terms = [LECol.HIV_AIDS, STATUS_DUMMY]
if econ_pc1 is not None:
    main_terms.append(econ_pc1)
main_terms.extend([LECol.TOTAL_EXPENDITURE, LECol.ALCOHOL])
if immun_pc1 is not None:
    main_terms.append(immun_pc1)

rhs_main = " + ".join(str(t) for t in main_terms)
train_int = df_train[[LECol.TARGET, *main_terms]].dropna()

int_base = fit_additive(
    registry,
    train_int,
    name="m_interactions_base",
    terms=main_terms,
    refit=True,
)
display(int_base)

int_diag = fit_additive(
    registry,
    train_int,
    name="m_interactions_reduced",
    terms=main_terms,
    extra_terms=[f"{STATUS_DUMMY}:{LECol.ALCOHOL}"],
    refit=True,
)
display(int_diag)
```

```{python}
# | label: interaction-slopes
# | fig-cap: "Interaction plot: predicted alcohol slope by development status."
from ama_tlbx.plotting.regression_plots import plot_interaction_effect

plt.figure(figsize=(8, 4))
plot_interaction_effect(
    int_diag,
    x=str(LECol.ALCOHOL),
    by=STATUS_DUMMY,
    df=train_int,
)
plt.show()
```

```{python}
# | label: interaction-diagnostics
# | fig-cap: "Interaction model diagnostics."
int_diag.plot_residual_diags()
```

```{python}
# | label: tbl-interaction-vif
# | tbl-cap: "VIF table for the interaction model (collinearity check)."
display(int_diag.vif)
```

```{python}
# | label: tbl-interaction-compare
# | tbl-cap: "Interaction models compared (sorted by AIC)."
registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m_interactions_base", "m_interactions_reduced"]]
```

The interaction plot shows **opposing alcohol slopes** by development status: a mildly positive slope for developing countries and a negative slope for developed countries. In the interaction model, `alcohol` is positive (**+0.87 years per 1 SD**, p = 0.026; 95% CI **[0.11, 1.64]**) while the interaction term is negative (**-3.71**, p = 0.055; 95% CI **[-7.49, 0.08]**), implying a developed‑country slope of roughly **-2.84 years per 1 SD**. The model is jointly significant (F‑test p < 0.001), but normality fails (JB p = 0.002; Shapiro p = 0.006) and BP indicates heteroskedasticity (BP p = 0.002), so p‑values/CIs should be treated cautiously. Collinearity is substantial (max VIF **12.6**, @tbl-interaction-vif), which inflates SEs and weakens stability. We therefore treat effect modification as **exploratory** and do not use this interaction specification as the chapter’s final interpretable model.

## Influence and outliers

**RQ6:** evaluate sensitivity to influential countries using Cook’s distance and leverage.

Trimmed refit: same formula as the nonlinearity model, estimated after excluding observations with Cook’s distance > 4/n.

```{python}
# | label: influence-sensitivity
# | code-fold: true
threshold = 4 / len(nl_df)
sens_initial, sens_diag = registry.fit(
    nl_df,
    name="m_nonlinear_linear_trimmed",
    rhs=rhs_linear,
    refit=True,
    cook_distance_threshold=threshold,
)
display(sens_diag)
```

Trimming a small set of influential observations (Cook’s distance > 4/n) is a simple sensitivity check. In our data this removes **13 countries** (179 $\rightarrow$ 166 observations). The trimmed model remains jointly significant (F‑test p < 0.001) with stable key effects (`hiv_aids` **-3.59** years; 95% CI **[-4.21, -2.97]**, `total_expenditure` **+1.21** years; 95% CI **[0.64, 1.77]**, `immunization_PC1` **-1.00** years; 95% CI **[-1.35, -0.66]**). Normality is acceptable (JB p = 0.307; Shapiro p = 0.129), but BP still flags heteroskedasticity (BP p = 0.012), so CIs may still be conservative. The largest absolute coefficient change is about **0.86 years** (for `status_developed`), and holdout RMSE changes only marginally (**4.01 $\rightarrow$ 4.02 years**). The influence plots suggest outliers concentrated in a few high‑leverage countries (e.g., **Lesotho**, **Eswatini**, **South Africa**, **Nigeria**), but the main coefficient signs remain stable, supporting the qualitative conclusions of the baseline model.

```{python}
# | label: tbl-influence-compare
# | tbl-cap: "Influence sensitivity: base vs trimmed nonlinearity model."
registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m_nonlinear_linear", "m_nonlinear_linear_trimmed"]]
```

## Generalization and holdout performance

**RQ7:** evaluate predictive performance on 2011.

```{python}
# | label: holdout-eval
# | code-fold: true
from ama_tlbx.analysis.ols_helper import EvalMetrics

eval_results = registry.evaluate_all(holdout_scaled, label=f"year{HOLDOUT_YEAR}")
eval_tbl = EvalMetrics.collate_to_df(list(eval_results.values()))
eval_tbl.insert(0, "model", list(eval_results.keys()))
eval_tbl = eval_tbl.set_index("model").sort_values("rmse")
eval_tbl.round(3)

compare_tbl = registry.compare(sort_by=f"year{HOLDOUT_YEAR}_rmse")
```

On the 2011 holdout year, the `adult_mortality` benchmark yields the lowest RMSE (**2.89 years**), which is expected because it is very close to the definition of life expectancy. Among the interpretability‑focused models, the **nonlinearity** and **immunization** specifications generalize similarly well (RMSE **4.12** vs **4.12** years), while the alcohol/BMI model performs worst (RMSE **5.84** years). The calibration view in @fig-holdout-calibration shows a mild **S‑shape**: the model tends to **underpredict** life expectancy for the lowest predicted values and slightly **overpredict** around the mid‑range, while high‑end predictions are close to the diagonal. This supports using the burden + development + immunization block as a **parsimonious** generalizable model, but also signals some remaining nonlinear structure.

```{python}
# | label: tbl-global-compare
# | tbl-cap: "Global model comparison (train fit + holdout metrics), sorted by holdout RMSE."
holdout_rmse_col = f"year{HOLDOUT_YEAR}_rmse"
compare_tbl.dropna(subset=[holdout_rmse_col]).sort_values(holdout_rmse_col).round(3)
```

The global comparison in @tbl-global-compare confirms the pattern above: the `adult_mortality` benchmark dominates pure predictive accuracy, while the **nonlinearity** and **immunization** models offer the best interpretability‑performance trade‑off among the multi‑predictor specifications.

```{python}
# | label: fig-holdout-calibration
# | fig-cap: "Observed vs predicted life expectancy on holdout year (best interpretable model)."
candidate_models = [
    "m_immunization_reduced",
    "m_nonlinear_linear",
    "m_alcohol_bmi",
]
best_name = (
    compare_tbl.loc[candidate_models, holdout_rmse_col].dropna().idxmin()
    if candidate_models
    else compare_tbl[holdout_rmse_col].dropna().idxmin()
)

metrics = registry.get(best_name).eval_metrics_by_label[f"year{HOLDOUT_YEAR}"]
plt.figure(figsize=(7, 5))
metrics.plot_calibration(bins=10, bootstrap=300, random_state=42)
plt.show()
```

## Panel regression and autocorrelation

**RQ8:** fit a model on the full panel and evaluate residual autocorrelation (Durbin–Watson). Interpret carefully; panel dependence is expected.

Model: `life_expectancy ~ adult_mortality + hiv_aids + status_developed` (panel)

```{python}
# | label: panel-model
# | code-fold: true
panel_registry = ModelRegistry()
panel_ds = LifeExpectancyDataset.from_csv_updated(
    aggregate_by_country=False,
    resolve_nand_pred="carry_forward",
)

panel_df = panel_ds.tf_and_norm().drop(columns=[LECol.YEAR])
if STATUS_DUMMY not in panel_df.columns and LECol.STATUS in panel_df.columns:
    panel_df = panel_df.assign(**{STATUS_DUMMY: panel_df[LECol.STATUS].astype(int)})

panel_cols = [LECol.TARGET, LECol.ADULT_MORTALITY, LECol.HIV_AIDS, STATUS_DUMMY]
panel_train = panel_df[panel_cols].dropna()

panel_diag = fit_additive(
    panel_registry,
    panel_train,
    name="m_panel",
    terms=[LECol.ADULT_MORTALITY, LECol.HIV_AIDS, STATUS_DUMMY],
)
display(panel_diag)
```

```{python}
# | label: tbl-panel-compare
# | tbl-cap: "Panel model summary (single model)."
panel_registry.compare(sort_by="aic").drop(columns=["rhs"])[
    ["aic", "rmse", "r2", "adj_r2", "n_obs"]
].loc[["m_panel"]]
```

The Durbin–Watson statistic is far below 2 (**DW = 0.48**), indicating strong positive autocorrelation in the panel residuals. The model is jointly significant (F‑test p < 0.001) with sizable effects (e.g., `adult_mortality` **-2.62** years per 1 SD, 95% CI **[-2.92, -2.33]**; `hiv_aids` **-4.43**, CI **[-4.72, -4.14]**; `status_developed` **+6.20**, CI **[5.55, 6.84]**), but autocorrelation and heteroskedasticity (BP p < 0.001; White p < 0.001) violate OLS assumptions. As a result, standard errors and CIs are not reliable in the pooled panel fit (despite $R^2 = 0.709$ and RMSE = 4.71 years). We keep the panel model only as a descriptive sensitivity check and base inference on the cross‑sectional models. A rigorous panel treatment would require country‑clustered or time‑clustered standard errors, or an explicit panel model (fixed effects / random effects / GLS with AR(1) errors), which is outside the scope of this chapter.

## Summary and limitations

Across the 2014 cross-section, we find a clear hierarchy of associations with life expectancy:

- **RQ1 (strongest association):** `adult_mortality` is the single strongest predictor (coef **-7.70 years per 1 SD**, $R^2 = 0.904$), but it is too close to the definition of life expectancy to serve as an interpretable “driver”.
- **RQ2 (socioeconomic-only prediction):** a socioeconomic baseline already captures a large share of the life expectancy gradient (see @tbl-socioeconomic-compare). The best AIC baseline is `m_socio_eco_undp_quad` (AIC **894.2**, RMSE **3.47 years**), and its 2011 calibration/uncertainty is summarized in @fig-socioeconomic-calibration and @tbl-socioeconomic-eval-ci.
- **RQ3 (immunization impact):** adding `immunization_PC1` improves fit beyond development status, HIV/AIDS burden, and economic development ($R^2$: **0.743 $\rightarrow$ 0.792**; RMSE: **4.11 $\rightarrow$ 3.69** years), with a sizeable immunization component (coef **-1.17 years per 1 SD**, p < 0.001).
- **RQ4 (alcohol/BMI conditional effects):** `bmi` remains positively associated after controls (coef **+1.93**, p < 0.001), while `alcohol` is not robustly different from zero (coef **-0.33**, p = 0.514).
- **RQ5 (effect modification):** the status × alcohol point estimate suggests a sign flip, but the interaction term is only marginal (coef **-3.71**, p = 0.055) once economic development is controlled for; we treat this as exploratory and do not retain interaction terms in the final model.
- **RQ6 (influence/outliers):** trimming **13** high-Cook’s observations changes coefficients modestly (max |Δcoef| $\approx$ 0.86 years) and does not materially change holdout RMSE (4.12 $\rightarrow$ 4.12 years).
- **RQ7 (generalization):** on the 2011 holdout year, the adult‑mortality benchmark generalizes best (RMSE **2.89** years); among interpretable models, nonlinearity and immunization are best (RMSE **4.12** years), while alcohol/BMI is worst (RMSE **5.84** years).
- **RQ8 (panel autocorrelation):** pooled panel OLS shows strong autocorrelation (DW = 0.48), so inference from the panel model is not reliable without a dedicated panel/cluster-robust treatment.

**Limitations.** All findings are descriptive associations in observational data. Several models violate homoscedasticity, and some violate residual normality; we therefore emphasize effect sizes, diagnostics, and sensitivity checks over marginal p-values. Finally, PCA components are linear combinations with arbitrary sign, so interpreting `*_PC1` coefficients requires inspecting loadings (see PCA-related chapters).
