---
title: "Regression"
format:
  html:
    toc: true
---

```{python}
# | label: init
# | fig-cap: "Dataset loading function hidden"
# | include: false
from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.graphics.regressionplots import influence_plot
import statsmodels.api as sm

from ama_tlbx.data import LifeExpectancyDataset, LECol

dataset = LifeExpectancyDataset.from_csv(
    resolve_nand_pred="carry_forward",
    aggregate_by_country=2011,
)

dataset_latest = LifeExpectancyDataset.from_csv(
    resolve_nand_pred="carry_forward",
    aggregate_by_country=2014,
)

assert not dataset.df.empty
assert not dataset_latest.df.empty

from ama_tlbx.analysis import (
    ColumnConcatenator,
)

# Concatenate columns for 2014 dataset
column_concatinator = ColumnConcatenator(dataset)
dataset2 = column_concatinator.concatenate(
    columns=[
        LECol.HEPATITIS_B,
        LECol.POLIO,
        LECol.DIPHTHERIA,
    ],
    new_column_name="Immunisation",
)

column_concatinator2 = ColumnConcatenator(dataset2)
dataset3 = column_concatinator2.concatenate(
    columns=[
        LECol.THINNESS_1_19_YEARS,
        LECol.THINNESS_5_9_YEARS,
    ],
    new_column_name="Child Thinness",
)

column_concatinator3 = ColumnConcatenator(dataset3)
dataset4 = column_concatinator3.concatenate(
    columns=[
        LECol.INFANT_DEATHS,
        LECol.UNDER_FIVE_DEATHS,
    ],
    new_column_name="Baby Deaths",
)
concat_dataset = dataset4

# Concatenate columns for latest dataset
column_concatinator_latest = ColumnConcatenator(dataset_latest)
dataset2_latest = column_concatinator_latest.concatenate(
    columns=[
        LECol.HEPATITIS_B,
        LECol.POLIO,
        LECol.DIPHTHERIA,
    ],
    new_column_name="Immunisation",
)

column_concatinator2_latest = ColumnConcatenator(dataset2_latest)
dataset3_latest = column_concatinator2_latest.concatenate(
    columns=[
        LECol.THINNESS_1_19_YEARS,
        LECol.THINNESS_5_9_YEARS,
    ],
    new_column_name="Child Thinness",
)

column_concatinator3_latest = ColumnConcatenator(dataset3_latest)
dataset4_latest = column_concatinator3_latest.concatenate(
    columns=[
        LECol.INFANT_DEATHS,
        LECol.UNDER_FIVE_DEATHS,
    ],
    new_column_name="Baby Deaths",
)
concat_dataset_latest = dataset4_latest

assert not concat_dataset.df.empty
assert not concat_dataset_latest.df.empty

df = concat_dataset.df
df_latest = concat_dataset_latest.df
```

# Regression Analysis

Performing regression on data is a common analysis method often used in attempt to derive and predict the life expectency using similar yet unknown data. Since the project primarely focuses on finding information as it pertains to life expectency, our regression analysis will fucus on predicting life expectency.

## Liniar Regression Analyis

Liniar regession is a common analysis performed on liniar data. Since life expectency is "mostly" liniar data, it is very fitting to use it to predict life expectency. The regression analysis has 5 parts each described in the figure below.

```{python}
# | label: liniar-reg
# | fig-cap: "Process for regression"

# 1: Drop rows where target is missing
target_col = LECol.LIFE_EXPECTANCY
reg_df = df.dropna(subset=[target_col])

# 2: Select features (numeric only, excluding target)
X = reg_df.select_dtypes(include=['number']).drop(columns=[target_col])
y = reg_df[target_col]

# 3: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4: Train model
model = LinearRegression()
model.fit(X_train, y_train)

# 5: Predict
y_pred = model.predict(X_test)
```

The six step process for the regeression analysis is as follows:
1. Defined the target variable we wish to estimate, here it is the Life expectency stored as an enum. We also drop all NA Columns since they cannot be used in a regression algorithm.
2. We extract all numeric features from the dataset excluding the target column to ensure contamination of data.
3. Split the dataset into train and test.
4. Train the model
5. Make predictions for analysis.

Afterwards we can perform a summary analysis using the OLS libary to guage our model capabilities.

```{python}
# | label: regression-summary
# | fig-cap: "Detailed Regression Summary"

# Fit OLS model with statsmodels for detailed summary
X_train_sm = sm.add_constant(X_train)
# Set index to country names for better labeling
X_train_sm.index = y_train.index
ols_model = sm.OLS(y_train, X_train_sm).fit()
# Store country names for later use in influence plot
country_names = reg_df[LECol.COUNTRY] if LECol.COUNTRY in reg_df.columns else reg_df.index

print(ols_model.summary())
```

Based on our OLS Regression result we get an `R-Squared: 0.937` Which means that the model explains 93% of the variance of the dataset. `Adj. R-Squared: 0.927` Shows that if you adjust for the number of features the amount still remains high. Showing that the majority of features play a signficant part of the analysis.

```{python}
# | label: liniar-reg-fig
# | echo: false
# | fig-cap: "Plot of how accurate our coefifients are on test data"


plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Life Expectancy')
plt.ylabel('Predicted Life Expectancy')
plt.title('Multivariate Regression: Actual vs Predicted')
plt.tight_layout()
plt.show()

```

The graph above tells a similar story showing a comparison between a countries predicted life expectency and it's actual expecetency on the test set, showing a strong fit given the data. The same strong fit that was shown previously.

### Residual Analysis

Performing a residual analysis allows us to analyse and gather an understanding of datapoints lying outside the predictions by the models. Residuals are calculated by subtracting the prediction from the test data. When a regression model is good the residuals should be random indicating that there is no missing data being modelled.

```{python}
# | label: residual-analysis
# | fig-cap: "Residual Analysis"
# | echo: false

residuals = y_test - y_pred

# Plot-Setup
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# --- Plot 1: Residuals vs. Test --
sns.scatterplot(x=y_pred, y=residuals, ax=axes[0], alpha=0.6)
axes[0].axhline(0, color='red', linestyle='--')
axes[0].set_xlabel('Predicted Life expectency')
axes[0].set_ylabel('Residuals')
axes[0].set_title('Residuals for the Fitted Values\n')

# --- Plot 2: Q-Q Plot ---
stats.probplot(residuals, dist="norm", plot=axes[1])
axes[1].set_title('Q-Q Plot\n')
axes[1].get_lines()[0].set_markerfacecolor('C0')
axes[1].get_lines()[0].set_markeredgewidth(0)

plt.tight_layout()
plt.show()
```

Based on the analysis the residuals looks completly random which is a good look and shows that there is no systematic mispredictions.

Creating an influence plot is a great way to get an idea for which countries and their respective residuals are the cause for the outliers/residuals. Our X axis "Leverage" shows us which residuals have high leverage over our regression analysis and are causes for analysis. The Y represents how much of an outlier the residual is. We aim to avoid `|y| < 2`. The size

```{python}
# | label: diag-result
# | fig-cap: "Residual Diagnostics Result"
# | echo: false

from matplotlib import pyplot as plt

# Create a proper mapping: original dataframe index -> country name
if LECol.COUNTRY in reg_df.columns:
    idx_to_country = dict(zip(reg_df.index, reg_df[LECol.COUNTRY]))
else:
    idx_to_country = {i: str(i) for i in reg_df.index}

fig, ax = plt.subplots(figsize=(7, 5))
influence_plot(ols_model, criterion="cooks", ax=ax)

# Process all text labels
for txt in ax.texts:
    txt_content = txt.get_text().strip()

    # Only process if it looks like a pure integer (not a decimal like Cook's distance)
    if txt_content.isdigit():
        try:
            obs_num = int(txt_content)

            # Try to get country name
            if obs_num < len(y_train):
                original_idx = y_train.index[obs_num]
                country = idx_to_country.get(original_idx, None)

                if country:
                    txt.set_text(str(country))
                    txt.set_fontsize(7)
                else:
                    # No country found - hide it
                    txt.set_visible(False)
            else:
                # Index out of bounds - hide it
                txt.set_visible(False)
        except:
            # Any error - hide it
            txt.set_visible(False)

plt.title("Influence Plot (Cook's Distance)")
plt.xlabel("Leverage")
plt.ylabel("Studentized Residuals")
plt.tight_layout()
plt.show()
```

We see that after performing the analysis that the majority of the residuals remain within the `|y| < 2` range showing a good fit. This is especially good since a lot of them are clumped towards `leverage = 0`. Indicating that each residual isn't being an extreme outliner.

The last noteworthy outliers are Ukraine, Venezuela and Bolivia. All countries with a large circle and sitting at high leverage. But still within the `|y| > 2` showing a good sign of fitness. Although further analysis could be performed here.

### Predictive capabilities

To test some predictive capabilites we decided to perform some single variable analyses, here we chose `income_composition_of_resources` because of it's coefficient of `7.0218`, which is the highest besides the constant which cant model anything itself.

```{python}
# | label: pred-plot-function
# | echo: false

def pred_plot(model, feature_col, df):
    """Plot actual vs predicted values for a single feature regression"""
    feature_name = str(feature_col)

    # Get predictions with confidence intervals
    predictions = model.get_prediction(df)
    pred_summary = predictions.summary_frame(alpha=0.05)  # 95% CI

    # Sort by feature for clean line plots
    sort_idx = df[feature_name].argsort()
    x_sorted = df[feature_name].iloc[sort_idx]

    plt.figure(figsize=(10, 6))

    # Plot actual data
    plt.scatter(df[feature_name], df['life_expectancy'], alpha=0.6, label='Actual', zorder=3)

    # Plot regression line
    plt.plot(x_sorted, pred_summary['mean'].iloc[sort_idx],
             color='red', linewidth=2, label='Regression Line', zorder=2)

    # Plot 95% confidence interval
    plt.fill_between(x_sorted,
                     pred_summary['mean_ci_lower'].iloc[sort_idx],
                     pred_summary['mean_ci_upper'].iloc[sort_idx],
                     alpha=0.2, color='red', label='95% CI', zorder=1)

    plt.xlabel(feature_name.replace('_', ' ').title())
    plt.ylabel('Life Expectancy')
    plt.title(f'Life Expectancy vs {feature_name.replace("_", " ").title()}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
```
```{python}
# | label: prediction-income-composition
# | fig-cap: prediction_icr
# | echo: false

pred = f"{LECol.HDI}"
model = sm.formula.ols(f"life_expectancy ~ {pred}", data=df).fit()

print(model.summary())
pred_plot(model, LECol.HDI, df)

```

In the plot for income composition of resources we see a very narrow 95% CI which would be good if it weren't for the majority of the daty lies outside of this bound meaning that this predicter alone is not sufficient to estimate life expectency.
This is what we would expect given that the original analyis shows a `Adj. R-Squared: 0.927`. Although the trendline in the model does show a clear positive correlation between the two, which matches a sanity check.

## Comparison: 2011 vs 2014 Data

To understand how well regression models generalize across time, we compare three scenarios using data from 2011 ("Old") and 2014 ("Latest"). This cross-temporal analysis reveals whether the relationships between predictors and life expectancy remain stable over time.

The 2011 model achieves `R² = 0.892` on its own test data, demonstrating strong predictive power for that year. The 2014 model, trained on data three years later, shows `R² = 0.786` on its test set—still a good result, explaining nearly 79% of the variance, though noticeably lower than the 2011 model. This difference could reflect changes in data quality, sample size, or the relationships between variables over time.  

```{python}
# | label: comparison-models
# | fig-cap: "Comparing 2014 vs Latest Year Models"
# | echo: false

# Prepare old data
reg_df_old = df.dropna(subset=[LECol.LIFE_EXPECTANCY])
X_old = reg_df_old.select_dtypes(include=['number']).drop(columns=[LECol.LIFE_EXPECTANCY])
y_old = reg_df_old[LECol.LIFE_EXPECTANCY]

# Prepare latest year data
reg_df_latest = df_latest.dropna(subset=[LECol.LIFE_EXPECTANCY])
X_latest = reg_df_latest.select_dtypes(include=['number']).drop(columns=[LECol.LIFE_EXPECTANCY])
y_latest = reg_df_latest[LECol.LIFE_EXPECTANCY]

# Train/test split for both datasets
X_train_old, X_test_old, y_train_old, y_test_old = train_test_split(
    X_old, y_old, test_size=0.2, random_state=42
)
X_train_latest, X_test_latest, y_train_latest, y_test_latest = train_test_split(
    X_latest, y_latest, test_size=0.2, random_state=42
)

# Fit old model
model_old = LinearRegression()
model_old.fit(X_train_old, y_train_old)
y_pred_old_on_old = model_old.predict(X_test_old)

# Fit latest year model
model_latest = LinearRegression()
model_latest.fit(X_train_latest, y_train_latest)
y_pred_latest_on_latest = model_latest.predict(X_test_latest)

# Apply old model to latest year data (cross-temporal prediction)
y_pred_old_on_latest = model_old.predict(X_test_latest)

# Calculate metrics for old model on its own data
r2_old_on_old = r2_score(y_test_old, y_pred_old_on_old)
rmse_old_on_old = np.sqrt(mean_squared_error(y_test_old, y_pred_old_on_old))

# Calculate metrics for latest model on its own data
r2_latest_on_latest = r2_score(y_test_latest, y_pred_latest_on_latest)
rmse_latest_on_latest = np.sqrt(mean_squared_error(y_test_latest, y_pred_latest_on_latest))

# Calculate metrics for old model applied to latest data
r2_old_on_latest = r2_score(y_test_latest, y_pred_old_on_latest)
rmse_old_on_latest = np.sqrt(mean_squared_error(y_test_latest, y_pred_old_on_latest))

# Create comparison dataframe
comparison = pd.DataFrame({
    'Model': ['Old → Old test', 'Latest → Latest test', 'Old → Latest test'],
    'R² Score': [r2_old_on_old, r2_latest_on_latest, r2_old_on_latest],
    'RMSE': [rmse_old_on_old, rmse_latest_on_latest, rmse_old_on_latest],
    'Training Size': [len(y_train_old), len(y_train_latest), len(y_train_old)],
    'Test Size': [len(y_test_old), len(y_test_latest), len(y_test_latest)]
})

print("\nModel Performance Comparison:")
print(comparison.to_string(index=False))
```

```{python}
# | label: comparison-plots
# | fig-cap: "Comparison of Model Predictions: 2014 Model on Both Datasets"
# | echo: false

fig = plt.figure(figsize=(8, 8))
gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
ax1 = fig.add_subplot(gs[0, 0])
ax2 = fig.add_subplot(gs[0, 1])
ax3 = fig.add_subplot(gs[1, :])

# Old model on old data
ax1.scatter(y_test_old, y_pred_old_on_old, alpha=0.5)
ax1.plot([y_test_old.min(), y_test_old.max()], 
         [y_test_old.min(), y_test_old.max()], 'r--', lw=2)
ax1.set_xlabel('Actual Life Expectancy')
ax1.set_ylabel('Predicted Life Expectancy')
ax1.set_title(f'Old Model on Old Data\n(R² = {r2_old_on_old:.3f})')
ax1.grid(True, alpha=0.3)

# Latest model on latest data
ax2.scatter(y_test_latest, y_pred_latest_on_latest, alpha=0.5, color='green')
ax2.plot([y_test_latest.min(), y_test_latest.max()], 
         [y_test_latest.min(), y_test_latest.max()], 'r--', lw=2)
ax2.set_xlabel('Actual Life Expectancy')
ax2.set_ylabel('Predicted Life Expectancy')
ax2.set_title(f'Latest Model on Latest Data\n(R² = {r2_latest_on_latest:.3f})')
ax2.grid(True, alpha=0.3)

# Old model on latest data (cross-temporal)
ax3.scatter(y_test_latest, y_pred_old_on_latest, alpha=0.5, color='orange')
ax3.plot([y_test_latest.min(), y_test_latest.max()], 
         [y_test_latest.min(), y_test_latest.max()], 'r--', lw=2)
ax3.set_xlabel('Actual Life Expectancy (2014)')
ax3.set_ylabel('Predicted Life Expectancy (2011 Model)')
ax3.set_title(f'Old Model on Latest Data\n(R² = {r2_old_on_latest:.3f})')
ax3.grid(True, alpha=0.3)

plt.show()
```

The comparison reveals the temporal stability of our predictive models:

- **Old → Old test** (R² = 0.892): Strong baseline performance when the 2011 model predicts 2011 data
- **Latest → Latest test** (R² = 0.786): Good performance when the 2014 model predicts 2014 data, though lower than the 2011 baseline
- **Old → Latest test** (R² = 0.862): Surprisingly strong cross-temporal prediction—the 2011 model predicts 2014 data better than the 2014 model predicts its own data

The third scenario is particularly noteworthy: the 2011 model achieves R² = 0.862 when predicting 2014 data, which exceeds the 2014 model's performance on its own test set (0.786). This suggests that the relationships between health, economic, and social factors learned from 2011 data generalized remarkably well to 2014, indicating relatively stable predictive patterns over this three-year period. The superior performance could also reflect better data quality or a larger sample size in the 2011 dataset, allowing the model to learn more robust relationships.