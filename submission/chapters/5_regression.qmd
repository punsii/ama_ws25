---
title: "Regression"
format:
  html:
    toc: true
---

```{python}
# | label: init
# | fig-cap: "Dataset loading function hidden"
# | include: false
from pathlib import Path

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.graphics.regressionplots import influence_plot
import statsmodels.api as sm

from ama_tlbx.data import LifeExpectancyDataset, LECol

dataset = LifeExpectancyDataset.from_csv(
    resolve_nand_pred="carry_forward",
    aggregate_by_country=2011,
)

dataset_latest = LifeExpectancyDataset.from_csv(
    resolve_nand_pred="carry_forward",
    aggregate_by_country=2014,
)

assert not dataset.df.empty
assert not dataset_latest.df.empty


from ama_tlbx.analysis import (
    ColumnConcatenator,
)

# Concatenate columns for 2014 dataset
column_concatinator = ColumnConcatenator(dataset)
dataset2 = column_concatinator.concatenate(
    columns=[
        LECol.HEPATITIS_B,
        LECol.POLIO,
        LECol.DIPHTHERIA,
    ],
    new_column_name="Immunisation",
)

column_concatinator2 = ColumnConcatenator(dataset2)
dataset3 = column_concatinator2.concatenate(
    columns=[
        LECol.THINNESS_1_19_YEARS,
        LECol.THINNESS_5_9_YEARS,
    ],
    new_column_name="Child Thinness",
)

column_concatinator3 = ColumnConcatenator(dataset3)
dataset4 = column_concatinator3.concatenate(
    columns=[
        LECol.INFANT_DEATHS,
        LECol.UNDER_FIVE_DEATHS,
    ],
    new_column_name="Baby Deaths",
)
concat_dataset = dataset4

# Concatenate columns for latest dataset
column_concatinator_latest = ColumnConcatenator(dataset_latest)
dataset2_latest = column_concatinator_latest.concatenate(
    columns=[
        LECol.HEPATITIS_B,
        LECol.POLIO,
        LECol.DIPHTHERIA,
    ],
    new_column_name="Immunisation",
)

column_concatinator2_latest = ColumnConcatenator(dataset2_latest)
dataset3_latest = column_concatinator2_latest.concatenate(
    columns=[
        LECol.THINNESS_1_19_YEARS,
        LECol.THINNESS_5_9_YEARS,
    ],
    new_column_name="Child Thinness",
)

column_concatinator3_latest = ColumnConcatenator(dataset3_latest)
dataset4_latest = column_concatinator3_latest.concatenate(
    columns=[
        LECol.INFANT_DEATHS,
        LECol.UNDER_FIVE_DEATHS,
    ],
    new_column_name="Baby Deaths",
)
concat_dataset_latest = dataset4_latest

assert not concat_dataset.df.empty
assert not concat_dataset_latest.df.empty

# Keep untransformed versions for analyses that need original columns
df_raw = concat_dataset.df
df_latest_raw = concat_dataset_latest.df

# Create normalized versions for regression
df = concat_dataset.tf_and_norm()
df_latest = concat_dataset_latest.tf_and_norm()
```

# Regression Analysis

Performing regression on data is a common analysis method often used in attempt to derive and predict the life expectency using similar yet unknown data. Since the project primarely focuses on finding information as it pertains to life expectency, our regression analysis will fucus on predicting life expectency.

## Liniar Regression Analyis

Liniar regession is a common analysis performed on liniar data. Since life expectency is "mostly" liniar data, it is very fitting to use it to predict life expectency. The regression analysis has 5 parts each described in the figure below.

```{python}
# | label: liniar-reg
# | fig-cap: "Process for regression"

# 1: Drop rows where target is missing
target_col = LECol.LIFE_EXPECTANCY
reg_df = df.dropna(subset=[target_col])

# 2: Select features (numeric only, excluding target)
X = reg_df.select_dtypes(include=['number']).drop(columns=[target_col])
y = reg_df[target_col]

# 3: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4: Train model
model = LinearRegression()
model.fit(X_train, y_train)

# 5: Predict
y_pred = model.predict(X_test)
```

The six step process for the regeression analysis is as follows:
1. Defined the target variable we wish to estimate, here it is the Life expectency stored as an enum. We also drop all NA Columns since they cannot be used in a regression algorithm.
2. We extract all numeric features from the dataset excluding the target column to ensure contamination of data.
3. Split the dataset into train and test.
4. Train the model
5. Make predictions for analysis.

Afterwards we can perform a summary analysis using the OLS libary to guage our model capabilities.

```{python}
# | label: regression-summary
# | fig-cap: "Detailed Regression Summary"

# Fit OLS model with statsmodels for detailed summary
X_train_sm = sm.add_constant(X_train)
# Set index to country names for better labeling
X_train_sm.index = y_train.index
ols_model = sm.OLS(y_train, X_train_sm).fit()
# Store country names for later use in influence plot
country_names = reg_df[LECol.COUNTRY] if LECol.COUNTRY in reg_df.columns else reg_df.index

print(ols_model.summary())
```

Based on our OLS Regression result we get an `R-Squared: 0.937` Which means that the model explains 93% of the variance of the dataset. `Adj. R-Squared: 0.927` Shows that if you adjust for the number of features the amount still remains high. Showing that the majority of features play a signficant part of the analysis.

```{python}
# | label: liniar-reg-fig
# | echo: false
# | fig-cap: "Plot of how accurate our coefifients are on test data"


plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Life Expectancy')
plt.ylabel('Predicted Life Expectancy')
plt.title('Multivariate Regression: Actual vs Predicted')
plt.tight_layout()
plt.show()

```

The graph above tells a similar story showing a comparison between a countries predicted life expectency and it's actual expecetency on the test set, showing a strong fit given the data. The same strong fit that was shown previously.

### Residual Analysis

Performing a residual analysis allows us to analyse and gather an understanding of datapoints lying outside the predictions by the models. Residuals are calculated by subtracting the prediction from the test data. When a regression model is good the residuals should be random indicating that there is no missing data being modelled.

```{python}
# | label: residual-analysis
# | fig-cap: "Residual Analysis"
# | echo: false

residuals = y_test - y_pred

# Plot-Setup
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# --- Plot 1: Residuals vs. Test --
sns.scatterplot(x=y_pred, y=residuals, ax=axes[0], alpha=0.6)
axes[0].axhline(0, color='red', linestyle='--')
axes[0].set_xlabel('Predicted Life expectency')
axes[0].set_ylabel('Residuals')
axes[0].set_title('Residuals for the Fitted Values\n')

# --- Plot 2: Q-Q Plot ---
stats.probplot(residuals, dist="norm", plot=axes[1])
axes[1].set_title('Q-Q Plot\n')
axes[1].get_lines()[0].set_markerfacecolor('C0')
axes[1].get_lines()[0].set_markeredgewidth(0)

plt.tight_layout()
plt.show()
```

Based on the analysis the residuals looks completly random which is a good look and shows that there is no systematic mispredictions.

Creating an influence plot is a great way to get an idea for which countries and their respective residuals are the cause for the outliers/residuals. Our X axis "Leverage" shows us which residuals have high leverage over our regression analysis and are causes for analysis. The Y represents how much of an outlier the residual is. We aim to avoid `|y| < 2`. The size

```{python}
# | label: diag-result
# | fig-cap: "Residual Diagnostics Result"
# | echo: false

from matplotlib import pyplot as plt

# Create a proper mapping: original dataframe index -> country name
if LECol.COUNTRY in reg_df.columns:
    idx_to_country = dict(zip(reg_df.index, reg_df[LECol.COUNTRY]))
else:
    idx_to_country = {i: str(i) for i in reg_df.index}

fig, ax = plt.subplots(figsize=(7, 5))
influence_plot(ols_model, criterion="cooks", ax=ax)

# Process all text labels
for txt in ax.texts:
    txt_content = txt.get_text().strip()

    # Only process if it looks like a pure integer (not a decimal like Cook's distance)
    if txt_content.isdigit():
        try:
            obs_num = int(txt_content)

            # Try to get country name
            if obs_num < len(y_train):
                original_idx = y_train.index[obs_num]
                country = idx_to_country.get(original_idx, None)

                if country:
                    txt.set_text(str(country))
                    txt.set_fontsize(7)
                else:
                    # No country found - hide it
                    txt.set_visible(False)
            else:
                # Index out of bounds - hide it
                txt.set_visible(False)
        except:
            # Any error - hide it
            txt.set_visible(False)

plt.title("Influence Plot (Cook's Distance)")
plt.xlabel("Leverage")
plt.ylabel("Studentized Residuals")
plt.tight_layout()
plt.show()
```

We see that after performing the analysis that the majority of the residuals remain within the `|y| < 2` range showing a good fit. This is especially good since a lot of them are clumped towards `leverage = 0`, indicating that each residual isn't being an extreme outlier.

The most notable outliers are **Austria**, **Malta**, and **India**. Austria and Malta show high studentized residuals (around 2-3) with moderate leverage, while India appears as a high-leverage point at the far right of the plot. However, most countries including **Sierra Leone**, **Lesotho**, and **Angola** (which show as large circles indicating high Cook's distance) remain within acceptable bounds (`|y| < 2`), suggesting the model is generally robust despite these influential points.

### Predictive capabilities

To test some predictive capabilities we decided to perform some single variable analyses, here we chose `Schooling` because it showed the strongest univariate relationship with life expectancy (R² = 0.601) among features that don't suffer from data leakage.

**Note on HDI Exclusion**: While Human Development Index showed the highest R² (0.799) in initial analysis, it was excluded from predictive modeling because HDI is calculated using life expectancy as one of its three components. Using HDI to predict life expectancy would constitute data leakage—using the target variable to predict itself—which artificially inflates performance and produces unreliable models.

```{python}
# | label: pred-plot-function
# | echo: false

def pred_plot(model, feature_col, df):
    """Plot actual vs predicted values for a single feature regression"""
    feature_name = str(feature_col)

    # Get predictions with confidence intervals
    predictions = model.get_prediction(df)
    pred_summary = predictions.summary_frame(alpha=0.05)  # 95% CI

    # Sort by feature for clean line plots
    sort_idx = df[feature_name].argsort()
    x_sorted = df[feature_name].iloc[sort_idx]

    plt.figure(figsize=(10, 6))

    # Plot actual data
    plt.scatter(df[feature_name], df['life_expectancy'], alpha=0.6, label='Actual', zorder=3)

    # Plot regression line
    plt.plot(x_sorted, pred_summary['mean'].iloc[sort_idx],
             color='red', linewidth=2, label='Regression Line', zorder=2)

    # Plot 95% confidence interval
    plt.fill_between(x_sorted,
                     pred_summary['mean_ci_lower'].iloc[sort_idx],
                     pred_summary['mean_ci_upper'].iloc[sort_idx],
                     alpha=0.2, color='red', label='95% CI', zorder=1)

    plt.xlabel(feature_name.replace('_', ' ').title())
    plt.ylabel('Life Expectancy')
    plt.title(f'Life Expectancy vs {feature_name.replace("_", " ").title()}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
```
```{python}
# | label: prediction-schooling
# | fig-cap: prediction_schooling
# | echo: false

pred = f"{LECol.SCHOOLING}"
model = sm.formula.ols(f"life_expectancy ~ {pred}", data=df).fit()

print(model.summary())
pred_plot(model, LECol.SCHOOLING, df)

```

In the plot for schooling we see a reasonably strong positive relationship with life expectancy. While the 95% confidence interval is relatively narrow, there is still considerable scatter around the regression line, indicating that schooling alone explains only about 60% of the variance (R² = 0.601). This demonstrates that while education is an important predictor, other factors are necessary for a comprehensive model of life expectancy. The clear positive trend confirms our expectation that countries with higher education levels tend to have longer life expectancies.

## Comparison: 2011 vs 2014 Data

To understand how well regression models generalize across time, we compare three scenarios using data from 2011 ("Old") and 2014 ("Latest"). This cross-temporal analysis reveals whether the relationships between predictors and life expectancy remain stable over time.

The 2011 model achieves `R² = 0.892` on its own test data, demonstrating strong predictive power for that year. The 2014 model, trained on data three years later, shows `R² = 0.786` on its test set—still a good result, explaining nearly 79% of the variance, though noticeably lower than the 2011 model. This difference could reflect changes in data quality, sample size, or the relationships between variables over time.

```{python}
# | label: comparison-models
# | fig-cap: "Comparing 2014 vs Latest Year Models"
# | echo: false

# Prepare old data
reg_df_old = df.dropna(subset=[LECol.LIFE_EXPECTANCY])
X_old = reg_df_old.select_dtypes(include=['number']).drop(columns=[LECol.LIFE_EXPECTANCY])
y_old = reg_df_old[LECol.LIFE_EXPECTANCY]

# Prepare latest year data
reg_df_latest = df_latest.dropna(subset=[LECol.LIFE_EXPECTANCY])
X_latest = reg_df_latest.select_dtypes(include=['number']).drop(columns=[LECol.LIFE_EXPECTANCY])
y_latest = reg_df_latest[LECol.LIFE_EXPECTANCY]

# Train/test split for both datasets
X_train_old, X_test_old, y_train_old, y_test_old = train_test_split(
    X_old, y_old, test_size=0.2, random_state=42
)
X_train_latest, X_test_latest, y_train_latest, y_test_latest = train_test_split(
    X_latest, y_latest, test_size=0.2, random_state=42
)

# Fit old model
model_old = LinearRegression()
model_old.fit(X_train_old, y_train_old)
y_pred_old_on_old = model_old.predict(X_test_old)

# Fit latest year model
model_latest = LinearRegression()
model_latest.fit(X_train_latest, y_train_latest)
y_pred_latest_on_latest = model_latest.predict(X_test_latest)

# Apply old model to latest year data (cross-temporal prediction)
y_pred_old_on_latest = model_old.predict(X_test_latest)

# Calculate metrics for old model on its own data
r2_old_on_old = r2_score(y_test_old, y_pred_old_on_old)
rmse_old_on_old = np.sqrt(mean_squared_error(y_test_old, y_pred_old_on_old))

# Calculate metrics for latest model on its own data
r2_latest_on_latest = r2_score(y_test_latest, y_pred_latest_on_latest)
rmse_latest_on_latest = np.sqrt(mean_squared_error(y_test_latest, y_pred_latest_on_latest))

# Calculate metrics for old model applied to latest data
r2_old_on_latest = r2_score(y_test_latest, y_pred_old_on_latest)
rmse_old_on_latest = np.sqrt(mean_squared_error(y_test_latest, y_pred_old_on_latest))

# Create comparison dataframe
comparison = pd.DataFrame({
    'Model': ['Old → Old test', 'Latest → Latest test', 'Old → Latest test'],
    'R² Score': [r2_old_on_old, r2_latest_on_latest, r2_old_on_latest],
    'RMSE': [rmse_old_on_old, rmse_latest_on_latest, rmse_old_on_latest],
    'Training Size': [len(y_train_old), len(y_train_latest), len(y_train_old)],
    'Test Size': [len(y_test_old), len(y_test_latest), len(y_test_latest)]
})

print("\nModel Performance Comparison:")
print(comparison.to_string(index=False))
```

```{python}
# | label: comparison-plots
# | fig-cap: "Comparison of Model Predictions: 2014 Model on Both Datasets"
# | echo: false

fig = plt.figure(figsize=(8, 8))
gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
ax1 = fig.add_subplot(gs[0, 0])
ax2 = fig.add_subplot(gs[0, 1])
ax3 = fig.add_subplot(gs[1, :])

# Old model on old data
ax1.scatter(y_test_old, y_pred_old_on_old, alpha=0.5)
ax1.plot([y_test_old.min(), y_test_old.max()],
         [y_test_old.min(), y_test_old.max()], 'r--', lw=2)
ax1.set_xlabel('Actual Life Expectancy')
ax1.set_ylabel('Predicted Life Expectancy')
ax1.set_title(f'Old Model on Old Data\n(R² = {r2_old_on_old:.3f})')
ax1.grid(True, alpha=0.3)

# Latest model on latest data
ax2.scatter(y_test_latest, y_pred_latest_on_latest, alpha=0.5, color='green')
ax2.plot([y_test_latest.min(), y_test_latest.max()],
         [y_test_latest.min(), y_test_latest.max()], 'r--', lw=2)
ax2.set_xlabel('Actual Life Expectancy')
ax2.set_ylabel('Predicted Life Expectancy')
ax2.set_title(f'Latest Model on Latest Data\n(R² = {r2_latest_on_latest:.3f})')
ax2.grid(True, alpha=0.3)

# Old model on latest data (cross-temporal)
ax3.scatter(y_test_latest, y_pred_old_on_latest, alpha=0.5, color='orange')
ax3.plot([y_test_latest.min(), y_test_latest.max()],
         [y_test_latest.min(), y_test_latest.max()], 'r--', lw=2)
ax3.set_xlabel('Actual Life Expectancy (2014)')
ax3.set_ylabel('Predicted Life Expectancy (2011 Model)')
ax3.set_title(f'Old Model on Latest Data\n(R² = {r2_old_on_latest:.3f})')
ax3.grid(True, alpha=0.3)

plt.show()
```

The comparison reveals the temporal stability of our predictive models:

- **Old → Old test** (R² = 0.892): Strong baseline performance when the 2011 model predicts 2011 data
- **Latest → Latest test** (R² = 0.786): Good performance when the 2014 model predicts 2014 data, though lower than the 2011 baseline
- **Old → Latest test** (R² = 0.862): Surprisingly strong cross-temporal prediction—the 2011 model predicts 2014 data better than the 2014 model predicts its own data

The third scenario is particularly noteworthy: the 2011 model achieves R² = 0.862 when predicting 2014 data, which exceeds the 2014 model's performance on its own test set (0.786). This suggests that the relationships between health, economic, and social factors learned from 2011 data generalized remarkably well to 2014, indicating relatively stable predictive patterns over this three-year period. The superior performance could also reflect better data quality or a larger sample size in the 2011 dataset, allowing the model to learn more robust relationships.

## Univariate Regression Application (2011)

To evaluate how well individual features predict life expectancy, we apply the 2011 model to perform single-variable regression analysis for each key predictor. This shows the relationship between each feature and life expectancy in isolation.

```{python}
# | label: monovariate-analysis
# | fig-cap: "Single Variable Regression Analysis using 2011 Data"
# | echo: false

data_to_analyse = [
    LECol.ALCOHOL,
    LECol.SCHOOLING,
    LECol.BMI,
    LECol.TOTAL_EXPENDITURE,
    LECol.PERCENTAGE_EXPENDITURE,
    LECol.GDP,
    LECol.POPULATION,
    LECol.HIV_AIDS,
    LECol.MEASLES,
    "Baby Deaths",
    "Child Thinness",
    "Immunisation",
]

# Calculate number of rows needed (2 columns per row)
n_features = len(data_to_analyse)
n_rows = (n_features + 1) // 2  # Ceiling division

fig, axes = plt.subplots(n_rows, 2, figsize=(8, n_rows * 3))
axes = axes.flatten()  # Flatten to make indexing easier

for idx, feature in enumerate(data_to_analyse):
    ax = axes[idx]

    # Prepare data for this feature
    feature_name = str(feature)
    df_feature = df[[feature_name, LECol.LIFE_EXPECTANCY]].dropna()

    # Fit single-variable model
    X_single = df_feature[[feature_name]]
    y_single = df_feature[LECol.LIFE_EXPECTANCY]

    model_single = LinearRegression()
    model_single.fit(X_single, y_single)
    y_pred_single = model_single.predict(X_single)

    # Calculate R² for this feature
    r2_single = r2_score(y_single, y_pred_single)

    # Sort for clean line plot
    sort_idx = X_single[feature_name].argsort()
    X_sorted = X_single.iloc[sort_idx]
    y_pred_sorted = y_pred_single[sort_idx]

    # Plot
    ax.scatter(X_single, y_single, alpha=0.5, s=30)
    ax.plot(X_sorted, y_pred_sorted, 'r-', linewidth=2, label=f'Regression Line')
    ax.set_xlabel(feature_name.replace('_', ' ').title())
    ax.set_ylabel('Life Expectancy')
    ax.set_title(f'{feature_name.replace("_", " ").title()}\n(R² = {r2_single:.3f})')
    ax.grid(True, alpha=0.3)
    ax.legend()

# Hide any unused subplots
for idx in range(n_features, len(axes)):
    axes[idx].set_visible(False)

plt.tight_layout()
plt.show()
```

The monovariate regression analysis reveals distinct patterns in how individual features predict life expectancy:

**Strong Predictors (R² > 0.5):**
- **Schooling (R² = 0.601)**: The strongest valid single predictor, showing a clear positive relationship. Education consistently correlates with better health outcomes, as countries with higher average years of schooling tend to have longer life expectancies.
- **HIV/AIDS (R² = 0.568)**: Strong negative correlation—higher HIV/AIDS prevalence significantly reduces life expectancy.

**Note**: Human Development Index was initially observed to have the highest R² (0.799), but was excluded from analysis because it incorporates life expectancy as one of its components, creating data leakage that would artificially inflate model performance.

**Moderate Predictors (0.1 < R² < 0.5):**
- **BMI (R² = 0.381)**: Shows a positive relationship with life expectancy. Higher average BMI typically indicates better nutrition and food security.
- **GDP (R² = 0.339)**: Economic output shows moderate predictive power, reflecting better healthcare access in wealthier nations.
- **Percentage Expenditure (R² = 0.319)**: Healthcare spending as a percentage of GDP shows moderate predictive power.
- **Child Thinness (R² = 0.203)**: Negative correlation as expected—higher malnutrition rates are associated with lower life expectancy, though the relationship is weaker than anticipated.
- **Alcohol (R² = 0.144)**: Shows a positive relationship, possibly because wealthier nations with better healthcare also have higher alcohol consumption, creating a confounding effect.

**Weak Predictors (R² < 0.1):**
- **Immunisation (R² = 0.091)**: Despite being health-critical, immunization alone shows weak predictive power in isolation. Most countries have reached high vaccination rates, reducing variance.
- **Baby Deaths (R² = 0.044)**: Very weak relationship, likely because this raw count is influenced by population size rather than mortality rates.
- **Measles (R² = 0.039)**: Very weak negative correlation, suggesting measles cases have minimal direct linear impact on life expectancy.
- **Total Expenditure (R² = 0.002)**: Essentially no linear relationship, suggesting health spending alone doesn't predict outcomes—how funds are allocated matters more than the amount spent.
- **Population (R² = 0.002)**: No meaningful linear relationship with life expectancy.

These results highlight why multivariate models outperform single-variable approaches. Features like Total Expenditure and Baby Deaths contribute meaningful information when combined with other predictors, even though they show minimal individual predictive power. The interaction between economic, social, and health factors provides a more complete picture than any single metric.

### Alcohol Consumption Analysis

To better understand the positive correlation between alcohol consumption and life expectancy (R² = 0.144 after normalization), we examine how this relationship differs between developed and developing countries.

```{python}
# | label: alcohol-by-status
# | fig-cap: "Alcohol Consumption vs Life Expectancy by Development Status"
# | echo: false

# Split data by status for alcohol analysis - use normalized data
# Note: STATUS is transformed to dummy variables (status_0, status_1) in normalized version
df_alcohol = df[[LECol.ALCOHOL, LECol.LIFE_EXPECTANCY]].dropna()

# Get status dummies from normalized dataframe
# status_0 = Developing (value 1 where true), status_1 = Developed (value 1 where true)
if 'status_0' in df.columns and 'status_1' in df.columns:
    df_alcohol = df[[LECol.ALCOHOL, LECol.LIFE_EXPECTANCY, 'status_0', 'status_1']].dropna()
    # Create mask: status_1 == 1 means Developed
    df_developed = df_alcohol[df_alcohol['status_1'] == 1].copy()
    df_developing = df_alcohol[df_alcohol['status_0'] == 1].copy()
else:
    # Fallback to raw data if status dummies not found
    df_alcohol_raw = df_raw[[LECol.ALCOHOL, LECol.LIFE_EXPECTANCY, LECol.STATUS]].dropna()
    df_developed = df_alcohol_raw[df_alcohol_raw[LECol.STATUS] == 1].copy()
    df_developing = df_alcohol_raw[df_alcohol_raw[LECol.STATUS] == 0].copy()
    # Need to normalize the features manually for consistency
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    df_developed[LECol.ALCOHOL] = scaler.fit_transform(df_developed[[LECol.ALCOHOL]])
    df_developing[LECol.ALCOHOL] = scaler.fit_transform(df_developing[[LECol.ALCOHOL]])

fig, ax = plt.subplots(figsize=(8, 5))

has_data = False

# Fit and plot developed countries
if len(df_developed) > 1:
    has_data = True
    X_dev = df_developed[[LECol.ALCOHOL]]
    y_dev = df_developed[LECol.LIFE_EXPECTANCY]

    model_dev = LinearRegression()
    model_dev.fit(X_dev, y_dev)
    y_pred_dev = model_dev.predict(X_dev)
    r2_dev = r2_score(y_dev, y_pred_dev)

    # Sort for line plot
    sort_idx = X_dev[LECol.ALCOHOL].argsort()
    X_sorted = X_dev.iloc[sort_idx]
    y_pred_sorted = y_pred_dev[sort_idx]

    # Plot
    ax.scatter(X_dev, y_dev, alpha=0.6, s=50, color='blue', label='Developed', edgecolors='darkblue', linewidth=0.5)
    ax.plot(X_sorted, y_pred_sorted, 'b-', linewidth=2.5, label=f'Developed (R²={r2_dev:.3f})')

# Fit and plot developing countries
if len(df_developing) > 1:
    has_data = True
    X_devg = df_developing[[LECol.ALCOHOL]]
    y_devg = df_developing[LECol.LIFE_EXPECTANCY]

    model_devg = LinearRegression()
    model_devg.fit(X_devg, y_devg)
    y_pred_devg = model_devg.predict(X_devg)
    r2_devg = r2_score(y_devg, y_pred_devg)

    # Sort for line plot
    sort_idx = X_devg[LECol.ALCOHOL].argsort()
    X_sorted = X_devg.iloc[sort_idx]
    y_pred_sorted = y_pred_devg[sort_idx]

    # Plot
    ax.scatter(X_devg, y_devg, alpha=0.6, s=50, color='orange', label='Developing', edgecolors='darkorange', linewidth=0.5)
    ax.plot(X_sorted, y_pred_sorted, color='darkorange', linewidth=2.5, label=f'Developing (R²={r2_devg:.3f})')

ax.set_xlabel('Alcohol Consumption (normalized)', fontsize=12)
ax.set_ylabel('Life Expectancy (years)', fontsize=12)
ax.set_title('Alcohol Consumption vs Life Expectancy by Development Status\n(Normalized Data)', fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)

if has_data:
    ax.legend(fontsize=10)

plt.tight_layout()
plt.show()
```

The stratified analysis using normalized data provides crucial insights into the alcohol-life expectancy relationship:

**Key Findings:**
- **Developed Countries (Blue, R² = 0.019)**: The regression line is nearly flat with a slight negative slope, and the extremely low R² indicates virtually no predictive relationship. Among developed nations (19 countries), alcohol consumption does not meaningfully predict life expectancy—these countries cluster at high life expectancy (mostly 80-87 years) regardless of normalized alcohol consumption levels (ranging from -2 to +1 standard deviations).

- **Developing Countries (Orange, R² = 0.037)**: Shows a weak positive correlation, though still with very low R². The much wider spread in life expectancy (50-85 years) across developing nations (112 countries) suggests that factors other than alcohol consumption are far more influential in determining outcomes. The normalized alcohol consumption shows greater variability (from -1.5 to +4 standard deviations), yet this explains less than 4% of life expectancy variance.

**Interpretation:**

When we examine the overall positive correlation (R² = 0.144) observed in the normalized combined data, separating by development status reveals that alcohol shows almost no predictive power within each group. The apparent correlation exists primarily because:

1. **Developed countries** (blue points at top) tend to cluster around normalized alcohol values near 0 (average consumption) with consistently high life expectancy (80+ years), showing a nearly flat or slightly negative trend
2. **Developing countries** (orange points) span a wider range of both alcohol consumption and life expectancy, but the weak positive slope (R² = 0.037) indicates alcohol is not a meaningful predictor
3. The overall correlation in combined data is driven by the **between-group differences** (developed vs developing) rather than the **within-group relationship** between alcohol and longevity

This demonstrates why stratified analysis is essential—the positive correlation disappears when controlling for development status, revealing alcohol as a poor predictor of life expectancy within similar economic contexts. The relationship is driven by confounding socioeconomic factors (healthcare quality, infrastructure, education) rather than any beneficial effect of alcohol consumption itself.

## Multivariate Regression Analysis

After examining individual predictors, we now combine the selected features to build a multivariate regression model. This allows us to see if the combined predictive power exceeds what any single variable can achieve.

```{python}
# | label: multivariate-analysis
# | fig-cap: "Multi Variable Regression Analysis using 2011 Data"
# | echo: false


# Prepare data with selected features
df_multi = df[data_to_analyse + [LECol.LIFE_EXPECTANCY]].dropna()
X_multi = df_multi[data_to_analyse]
y_multi = df_multi[LECol.LIFE_EXPECTANCY]

# Train/test split
X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(
    X_multi, y_multi, test_size=0.2, random_state=42
)

# Fit multivariate model
model_multi = LinearRegression()
model_multi.fit(X_train_multi, y_train_multi)
y_pred_multi = model_multi.predict(X_test_multi)

# Calculate metrics
r2_multi = r2_score(y_test_multi, y_pred_multi)
rmse_multi = np.sqrt(mean_squared_error(y_test_multi, y_pred_multi))

print(f"Multivariate Model Performance:")
print(f"R² Score: {r2_multi:.4f}")
print(f"RMSE: {rmse_multi:.4f}")
print(f"Number of features: {len(data_to_analyse)}")
print(f"Training samples: {len(y_train_multi)}")
print(f"Test samples: {len(y_test_multi)}")

# Create visualization with wider figure to accommodate labels
fig, axes = plt.subplots(1, 2, figsize=(8, 4))

# Plot 1: Actual vs Predicted
axes[0].scatter(y_test_multi, y_pred_multi, alpha=0.6, s=50)
axes[0].plot([y_test_multi.min(), y_test_multi.max()],
             [y_test_multi.min(), y_test_multi.max()], 'r--', lw=2, label='Perfect Prediction')
axes[0].set_xlabel('Actual Life Expectancy', fontsize=11)
axes[0].set_ylabel('Predicted Life Expectancy', fontsize=11)
axes[0].set_title(f'Multivariate Model: Actual vs Predicted\n(R² = {r2_multi:.4f})', fontsize=12, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].legend()

# Plot 2: Feature Coefficients
coefficients = pd.DataFrame({
    'Feature': [str(f).replace('_', ' ').title() for f in data_to_analyse],
    'Coefficient': model_multi.coef_
}).sort_values('Coefficient', key=abs, ascending=False)

# Create bar chart with adjusted margins
colors = ['green' if c > 0 else 'red' for c in coefficients['Coefficient']]
bars = axes[1].barh(coefficients['Feature'], coefficients['Coefficient'], color=colors, alpha=0.7)

# Add value labels on the bars with smart positioning
for i, (idx, row) in enumerate(coefficients.iterrows()):
    value = row['Coefficient']

    # Position labels to the right of bars to avoid overlap
    if value < 0:
        x_pos = max(-0.5,value - 0.15)  # Left of negative bars
        ha = 'right'
    else:
        x_pos = min(0.5,value + 0.15)  # Right of positive bars
        ha = 'left'

    axes[1].text(x_pos, i, f'{value:.2f}',
                va='center', ha=ha,
                fontsize=9, fontweight='bold', color='black')

axes[1].set_xlabel('Coefficient Value', fontsize=11)
axes[1].set_title('Feature Importance (Coefficients)', fontsize=12, fontweight='bold')
axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.8)
axes[1].grid(True, alpha=0.3, axis='x')
# Adjust subplot to prevent label cutoff
plt.subplots_adjust(left=0.15, right=0.95)

plt.tight_layout()
plt.show()
```

**Analysis:**

The multivariate model using normalized features achieves **R² = 0.7791**, which represents a substantial improvement over the best individual predictor (Schooling with R² = 0.601). This demonstrates the power of combining multiple features:

**Key Insights:**
1. **Synergistic Effects**: Features that showed weak individual predictive power (like Total Expenditure, R² = 0.002) contribute meaningfully when combined with other variables, capturing interaction effects that aren't visible in isolation.

2. **Feature Coefficients**: The bar chart reveals the strongest predictors after normalization:
   - **HIV/AIDS (-4.76)**: Strongest negative impact—diseases dramatically reduce life expectancy
   - **Schooling (+3.39)**: Strongest positive impact—education remains the most beneficial factor
   - **Percentage Expenditure (+1.85)**: Healthcare spending shows substantial positive effect
   - **Alcohol (+0.91)** and **GDP (-0.95)**: Moderate effects, though GDP's negative coefficient may reflect confounding
   - **Measles (-0.52)**, **Baby Deaths (-0.23)**: Smaller but still meaningful negative impacts
   - Other features show coefficients below ±0.3

3. **Normalization Impact**: The normalized model (R² = 0.7791) differs from the raw data model, as standardization changes how features interact. The coefficient magnitudes now reflect standardized units, making them directly comparable.

The difference reveals how much additional predictive power comes from features beyond our selected 7, suggesting that including more comprehensive health, economic, and demographic indicators improves the model further.

## Multivariate Regression with Outlier Removal

To assess whether extreme observations are disproportionately affecting our model, we now repeat the multivariate analysis after removing outliers based on studentized residuals. Countries with `|studentized residual| > 2` are excluded, which removes observations that deviate significantly from the model's predictions. This approach helps us understand whether the model's performance is driven by a few unusual cases or reflects genuine patterns across the majority of countries.

```{python}
# | label: multivariate-no-outliers
# | fig-cap: "Multivariate Regression with Outliers Removed (|y| > 2)"
# | echo: false

# Fit initial model to identify outliers
df_multi_clean = df[data_to_analyse + [LECol.LIFE_EXPECTANCY]].dropna()
X_multi_clean = df_multi_clean[data_to_analyse]
y_multi_clean = df_multi_clean[LECol.LIFE_EXPECTANCY]

# Fit OLS model to get studentized residuals
X_multi_clean_sm = sm.add_constant(X_multi_clean)
ols_model_clean = sm.OLS(y_multi_clean, X_multi_clean_sm).fit()

# Get studentized residuals
influence = ols_model_clean.get_influence()
studentized_resids = influence.resid_studentized_internal

# Remove outliers with |studentized residual| > 2
outlier_mask = np.abs(studentized_resids) <= 2
n_outliers_removed = (~outlier_mask).sum()

print(f"Outliers removed: {n_outliers_removed} countries (|studentized residual| > 2)")
print(f"Remaining samples: {outlier_mask.sum()} countries\n")

# Filter data
X_multi_clean = X_multi_clean[outlier_mask]
y_multi_clean = y_multi_clean[outlier_mask]

# Train/test split on cleaned data
X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(
    X_multi_clean, y_multi_clean, test_size=0.2, random_state=42
)

# Fit model on cleaned data
model_clean = LinearRegression()
model_clean.fit(X_train_clean, y_train_clean)
y_pred_clean = model_clean.predict(X_test_clean)

# Calculate metrics
r2_clean = r2_score(y_test_clean, y_pred_clean)
rmse_clean = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))

print(f"Model Performance (without outliers):")
print(f"R² Score: {r2_clean:.4f}")
print(f"RMSE: {rmse_clean:.4f}")
print(f"Training samples: {len(y_train_clean)}")
print(f"Test samples: {len(y_test_clean)}")
print(f"\nComparison to original model:")
print(f"Original R²: {r2_multi:.4f}")
print(f"Improvement: {(r2_clean - r2_multi):.4f} ({((r2_clean - r2_multi) / r2_multi * 100):.1f}%)")

# Create visualization
fig, axes = plt.subplots(1, 2, figsize=(8, 4))

# Plot 1: Actual vs Predicted (cleaned data)
axes[0].scatter(y_test_clean, y_pred_clean, alpha=0.6, s=50, color='steelblue')
axes[0].plot([y_test_clean.min(), y_test_clean.max()],
             [y_test_clean.min(), y_test_clean.max()], 'r--', lw=2, label='Perfect Prediction')
axes[0].set_xlabel('Actual Life Expectancy', fontsize=11)
axes[0].set_ylabel('Predicted Life Expectancy', fontsize=11)
axes[0].set_title(f'Without Outliers: Actual vs Predicted\n(R² = {r2_clean:.4f})', fontsize=12, fontweight='bold')
axes[0].grid(True, alpha=0.3)
axes[0].legend()

# Plot 2: Feature Coefficients (cleaned model)
coefficients_clean = pd.DataFrame({
    'Feature': [str(f).replace('_', ' ').title() for f in data_to_analyse],
    'Coefficient': model_clean.coef_
}).sort_values('Coefficient', key=abs, ascending=False)

colors_clean = ['green' if c > 0 else 'red' for c in coefficients_clean['Coefficient']]
bars = axes[1].barh(coefficients_clean['Feature'], coefficients_clean['Coefficient'], color=colors_clean, alpha=0.7)

# Add value labels
for i, (idx, row) in enumerate(coefficients_clean.iterrows()):
    value = row['Coefficient']

    if value < 0:
        x_pos = max(-0.5, value - 0.15)
        ha = 'right'
    else:
        x_pos = min(0.5, value + 0.15)
        ha = 'left'

    axes[1].text(x_pos, i, f'{value:.2f}',
                va='center', ha=ha,
                fontsize=9, fontweight='bold', color='black')

axes[1].set_xlabel('Coefficient Value', fontsize=11)
axes[1].set_title('Feature Importance (Without Outliers)', fontsize=12, fontweight='bold')
axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.8)
axes[1].grid(True, alpha=0.3, axis='x')
plt.subplots_adjust(left=0.15, right=0.95)

plt.tight_layout()
plt.show()
```

**Analysis:**

Removing outliers with studentized residuals `|y| > 2` reveals several important insights about model robustness:

**Model Performance:**
- The cleaned model achieves **R² = 0.8128** compared to R² = 0.7791 with outliers included
- This represents a **+0.0337 improvement (+4.3%)** in explained variance
- The tighter scatter around the perfect prediction line shows reduced prediction errors
- Removing extreme cases allows the model to better capture the core relationships for typical countries

**Coefficient Changes:**

Comparing the feature importance before and after outlier removal:

| Feature | Original | Without Outliers | Change |
|---------|----------|------------------|--------|
| **HIV/AIDS** | -4.76 | -4.70 | +0.06 (stable) |
| **Schooling** | +3.39 | +3.30 | -0.09 (stable) |
| **Percentage Expenditure** | +1.85 | +1.88 | +0.03 (stable) |
| **GDP** | -0.95 | -1.02 | -0.07 (stable) |
| **Alcohol** | +0.91 | +0.17 | -0.74 (reduced) |
| **BMI** | +0.31 | +0.62 | +0.31 (increased) |
| **Total Expenditure** | +0.03 | +0.50 | +0.47 (increased) |
| **Baby Deaths** | -0.23 | -0.20 | +0.03 (stable) |

**Key Findings:**

1. **Improved Predictive Power**: The R² improvement from 0.7791 to 0.8128 indicates that outliers were introducing noise rather than capturing genuine patterns. The model now explains 81% of variance in typical countries, up from 78%.

2. **Robust Core Predictors**: HIV/AIDS (-4.70), Schooling (+3.30), and Percentage Expenditure (+1.88) maintain their dominance and relative magnitudes. This confirms these relationships are consistent across all country types, not driven by extreme cases.

3. **Outlier-Sensitive Features**:
   - **Alcohol** coefficient dropped dramatically from +0.91 to +0.17, suggesting the positive alcohol-longevity relationship was largely driven by outlier countries
   - **BMI** and **Total Expenditure** became more important (+0.31 and +0.47 increases), indicating outliers were masking their true contributions

4. **Practical Implications**: For policy applications, the cleaned model is more reliable for predicting outcomes in typical development scenarios. The stability of HIV/AIDS, Schooling, and Healthcare Expenditure as top predictors reinforces their importance regardless of country context, while the alcohol relationship appears less robust and may reflect confounding rather than causal effects.
