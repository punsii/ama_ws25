---
title: "Introduction"
format:
  html:
    toc: true
---

# Life expectancy: motivation and scope

We analyze the WHO “Life Expectancy” dataset (Kaggle), which records country‑year health, economic, and immunization indicators alongside life expectancy.

To keep the multivariate methods (correlation, PCA, clustering, regression) close to their standard cross-sectional assumptions, we focus on a single year (2014). This reduces within‑country temporal dependence while retaining broad geographic coverage.

```{python}
# | label: intro-setup
# | include: false
import re

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from ama_tlbx.data import LECol, LifeExpectancyDataset
from ama_tlbx.utils.plotting_config import DEFAULT_PLOT_CFG

np.random.seed(42)

DEFAULT_PLOT_CFG.apply_global()

# Raw longitudinal panel (no dropping / no imputation)
le_panel = LifeExpectancyDataset.from_csv(
    aggregate_by_country=False,
    drop_missing_target=False,
    resolve_nand_pred=False,
)
df_panel = le_panel.df

# "Analysis-ready" panel (complete rows across numeric predictors + target)
le_panel_clean = LifeExpectancyDataset.from_csv(
    aggregate_by_country=False,
    drop_missing_target=True,
    resolve_nand_pred="drop",
)
df_panel_clean = le_panel_clean.df

# 2014 cross-section (complete-case across numeric predictors + target)
df_2014_full = df_panel[df_panel[LECol.YEAR].dt.year == 2014].copy()
numeric_cols_2014 = df_2014_full.select_dtypes(include=["number"]).columns.tolist()
df_2014 = df_2014_full.dropna(subset=numeric_cols_2014).set_index(LECol.COUNTRY)

# Basic dataset coverage (for the counts stated in the introduction)
dataset_coverage = pd.DataFrame(
    [
        {
            "view": "Raw panel (no dropping)",
            "n_rows": len(df_panel),
            "n_countries": df_panel[LECol.COUNTRY].nunique(),
            "years": f"{df_panel[LECol.YEAR].dt.year.min()}–{df_panel[LECol.YEAR].dt.year.max()}",
        },
        {
            "view": "Analysis-ready panel (drop missing)",
            "n_rows": len(df_panel_clean),
            "n_countries": df_panel_clean[LECol.COUNTRY].nunique(),
            "years": f"{df_panel_clean[LECol.YEAR].dt.year.min()}–{df_panel_clean[LECol.YEAR].dt.year.max()}",
        },
        {
            "view": "2014 cross-section (complete-case)",
            "n_rows": len(df_2014),
            "n_countries": len(df_2014),
            "years": "2014",
        },
    ],
)

# Life expectancy summary stats for the 2014 complete-case cross-section
life_expectancy_pretty = le_panel.get_pretty_name(str(LECol.TARGET))
life_expectancy_stats = (
    df_2014[LECol.TARGET].describe().loc[["count", "mean", "std", "min", "max"]]
)
life_expectancy_stats.index = ["N", "Mean", "SD", "Min", "Max"]
life_expectancy_stats = life_expectancy_stats.to_frame(name=life_expectancy_pretty).T
life_expectancy_stats["N"] = life_expectancy_stats["N"].astype(int)

# Correlations with target (complete-case 2014 cross-section)
corr_matrix_2014 = df_2014.select_dtypes(include=["number"]).corr(numeric_only=True)
target_corr_2014 = (
    corr_matrix_2014[str(LECol.TARGET)]
    .drop(str(LECol.TARGET))
    .sort_values(ascending=False)
    .to_frame(name="correlation")
    .assign(feature=lambda d: d.index)
    .assign(pretty=lambda d: d.feature.map(le_panel.get_pretty_name))
    .reset_index(drop=True)
)

pos5 = target_corr_2014.head(5).assign(direction="Positive")
neg5 = target_corr_2014.tail(5).assign(direction="Negative")
top_corr_2014 = (
    pd.concat([neg5, pos5], ignore_index=True)
    .assign(correlation=lambda d: d.correlation.astype(float))
    .sort_values("correlation")
)

# Multicollinearity hotspots referenced in text
hotspot_pairs = [
    (LECol.INFANT_DEATHS, LECol.UNDER_FIVE_DEATHS),
    (LECol.GDP, LECol.PERCENTAGE_EXPENDITURE),
    (LECol.THINNESS_5_9_YEARS, LECol.THINNESS_1_19_YEARS),
    (LECol.INCOME_COMPOSITION, LECol.SCHOOLING),
]
collinearity_hotspots = pd.DataFrame(
    [
        {
            "pair": f"`{str(a)}`–`{str(b)}`",
            "pretty_pair": f"{le_panel.get_pretty_name(str(a))} vs {le_panel.get_pretty_name(str(b))}",
            "correlation": float(corr_matrix_2014.loc[str(a), str(b)]),
        }
        for a, b in hotspot_pairs
    ],
).sort_values("correlation", ascending=False)

# Outlier screening: raw-scale z-scores on predictors (complete-case 2014 cross-section)
predictor_cols = (
    df_2014.select_dtypes(include=["number"])
    .columns.difference([str(LECol.TARGET), str(LECol.STATUS)])
    .tolist()
)
X = df_2014.loc[:, predictor_cols].astype(float)
z = (X - X.mean()) / X.std(ddof=0)
row_any_absz_gt3 = z.abs().gt(3).any(axis=1)

outlier_row_summary = pd.DataFrame(
    {
        "n_rows": [len(df_2014)],
        "n_rows_any_|z|>3": [int(row_any_absz_gt3.sum())],
        "share_%": [float(row_any_absz_gt3.mean() * 100)],
    }
)

outlier_feature_summary = (
    z.abs()
    .gt(3)
    .sum()
    .sort_values(ascending=False)
    .to_frame(name="n_values_|z|>3")
    .assign(feature=lambda d: d.index)
    .assign(pretty=lambda d: d.feature.map(le_panel.get_pretty_name))
    .reset_index(drop=True)
    .head(10)
)


def _transform_label(feature: str) -> str:
    try:
        col = LECol(feature)
    except ValueError:
        return "custom"

    transform = col.metadata().transform
    if transform is None:
        return "none"

    name = getattr(transform, "__name__", "custom")
    if name == "_log1p_under_coverage":
        return "log1p(100 - x)"
    if name == "log1p":
        return "log1p(x)"
    return name


def _parse_column_docstrings(doc: str) -> pd.DataFrame:
    rows: list[dict[str, str]] = []
    for raw_line in (doc or "").splitlines():
        line = raw_line.strip()
        if not line.startswith("- ``") or " - " not in line:
            continue
        left, desc = line.split(" - ", 1)
        name_part, dtype_part = left.split(": ", 1)
        name = name_part.replace("- ``", "").replace("``", "").strip()
        rows.append(
            {"column": name, "type": dtype_part.strip(), "description": desc.strip()}
        )
    return pd.DataFrame(rows)


column_glossary = (
    _parse_column_docstrings(LECol.__doc__ or "")
    .assign(pretty=lambda d: d.column.map(le_panel.get_pretty_name))
    .assign(transform=lambda d: d.column.map(_transform_label))
)
column_glossary.loc[column_glossary["column"] == str(LECol.STATUS), "description"] = (
    "Development status (0 = Developing, 1 = Developed)"
)

```

```{python}
# | label: tbl-intro-dataset-coverage
# | tbl-cap: "Dataset coverage summary (raw panel vs analysis-ready subset vs 2014 cross-section)."
dataset_coverage
```

## Outcome and predictors

All variables are reported at the country‑year level and come in mixed scales (counts, rates, percentages, and economic magnitudes). The target variable is `life_expectancy` (years). Predictors span four conceptual blocks:

1. **Demography & mortality**
   - **Adult Mortality (per 1000):** adult mortality rate per 1,000 population (probability of dying between ages 15 and 60).
   - **Infant Deaths (per 1000):** number of infant deaths per 1,000 population.
   - **Under‑5 Deaths (per 1000):** deaths of children under 5 per 1,000 population.
   - **HIV/AIDS Deaths (per 1000 births):** deaths per 1,000 live births due to HIV/AIDS (ages 0–4).
   - **Population:** total population of the country.

2. **Immunization & infectious disease burden**
   - **Hepatitis B Coverage (%):** HepB immunization coverage among 1‑year‑olds (%).
   - **Polio Coverage (%):** polio immunization coverage among 1‑year‑olds (%).
   - **Diphtheria Coverage (%):** DTP3 immunization coverage among 1‑year‑olds (%).
   - **Measles Cases (per 1000):** number of measles cases per 1,000 population.

3. **Socio‑economic & investment**
   - **GDP per Capita (USD):** gross domestic product per capita (USD).
   - **Health Expenditure (% of GDP per capita):** health spending as a percentage of GDP per capita.
   - **Total Health Expenditure (% of govt expenditure):** government health expenditure as a percentage of total government spending.
   - **Income Composition (HDI):** human development index component (0–1).
   - **Schooling (years):** average years of schooling.
   - **Alcohol Consumption (liters per capita):** recorded per‑capita (15+) consumption in liters of pure alcohol.

4. **Nutrition & development status**
   - **BMI (Average):** average body‑mass index.
   - **Thinness 10–19 Years (%):** prevalence of thinness among children ages 10–19 (%).
   - **Thinness 5–9 Years (%):** prevalence of thinness among children ages 5–9 (%).
   - **Development Status:** binary indicator (`0 = Developing`, `1 = Developed`), derived from the raw categorical status label.

::: {.callout-note collapse="true"}
## Column glossary (from `LifeExpectancyColumn`)

The table below summarizes column meanings and the default transforms applied later in the pipeline (`tf_and_norm`).

```{python}
# | label: tbl-intro-column-glossary
# | tbl-cap: "Column definitions and default preprocessing transforms."
column_glossary.loc[:, ["pretty", "description", "transform"]].rename(
    columns={
        "pretty": "Feature",
        "description": "Definition (units / scale)",
        "transform": "Default transform",
    },
)
```
:::

```{python}
# | label: fig-intro-status-gap
# | fig-cap: "Life expectancy by development status (2014 cross-section)."
plot_df = df_2014.assign(
    status_label=lambda d: d[LECol.STATUS].map({0: "Developing", 1: "Developed"}),
)

fig, ax = plt.subplots(figsize=(7, 4))
sns.boxplot(
    data=plot_df,
    x="status_label",
    y=LECol.LIFE_EXPECTANCY,
    ax=ax,
    color="lightgray",
)
sns.stripplot(
    data=plot_df,
    x="status_label",
    y=LECol.LIFE_EXPECTANCY,
    ax=ax,
    color="steelblue",
    alpha=0.6,
    jitter=True,
    size=4,
)
ax.set_xlabel("")
ax.set_ylabel("Life expectancy (years)")
ax.set_title("Development Status Gap")
plt.tight_layout()
plt.show()
```

## Descriptive snapshot (2014 cross-section)

```{python}
# | label: tbl-intro-lifeexp-summary
# | tbl-cap: "Life expectancy summary statistics (2014 cross-section, complete-case)."
life_expectancy_stats.round(2)
```

```{python}
# | label: fig-intro-lifeexp-dist
# | fig-cap: "Life expectancy distribution in the 2014 cross-section (complete-case)."
fig, ax = plt.subplots(figsize=(8, 4))
sns.histplot(
    df_2014[LECol.LIFE_EXPECTANCY],
    kde=True,
    ax=ax,
    color="steelblue",
    edgecolor="black",
)
ax.set_xlabel("Life expectancy (years)")
ax.set_ylabel("Count")
ax.set_title("Life Expectancy (2014)")
plt.tight_layout()
plt.show()
```

## Descriptive signal (2014 cross‑section, standardized)

In the complete-case 2014 cross‑section ($n=131$), mean life expectancy is 70.5 years (SD 8.6; range 48.1–89.0; Table @tbl-intro-lifeexp-summary). Pearson correlations are scale‑invariant, so the coefficients below are unchanged by z‑scoring. The strongest *positive* linear associations with `life_expectancy` are development indicators (income composition, schooling, status) and nutrition (BMI). The strongest *negative* associations are mortality/burden variables (adult mortality, HIV/AIDS, thinness indicators).

```{python}
# | label: fig-intro-top-corr
# | fig-cap: "Top 5 positive and negative correlations with life expectancy (2014)."
order = top_corr_2014.sort_values("correlation")["pretty"].tolist()

fig, ax = plt.subplots(figsize=(8, 5))
sns.barplot(
    data=top_corr_2014,
    x="correlation",
    y="pretty",
    hue="direction",
    order=order,
    dodge=False,
    palette="coolwarm",
    ax=ax,
)
ax.axvline(0, color="black", linewidth=1)
ax.set_xlabel("Correlation with life expectancy")
ax.set_ylabel("")
ax.set_title("Strongest Linear Associations")
ax.legend(title="")
plt.tight_layout()
plt.show()
```

```{python}
# | label: tbl-intro-top-corr
# | tbl-cap: "Top 5 positive and negative correlations with life expectancy (2014)."
top_corr_2014.assign(r=lambda d: d.correlation.round(2)).loc[:, ["pretty", "r"]].rename(
    columns={"pretty": "Feature", "r": "Correlation (r)"},
)
```

Several predictors are also *highly correlated with each other*, which motivates either feature grouping (PCA blocks) or careful interpretation of multivariate regression coefficients.

```{python}
# | label: tbl-intro-collinearity-hotspots
# | tbl-cap: "Selected multicollinearity hotspots (pairwise Pearson correlations; 2014 cross-section)."
collinearity_hotspots.assign(r=lambda d: d.correlation.round(3)).loc[:, ["pretty_pair", "r"]].rename(
    columns={"pretty_pair": "Pair", "r": "Correlation (r)"},
)
```

## Outlier screening (2014, z‑scores)

We screen for unusually extreme predictor profiles using raw-scale z‑scores (no transforms). A row is flagged if *any* predictor exceeds $|z| > 3$.

```{python}
# | label: tbl-intro-outlier-rows
# | tbl-cap: "Outlier summary (rows with any raw-scale |z| > 3)."
outlier_row_summary.assign(**{"share_%": lambda d: d["share_%"].round(1)})
```

```{python}
# | label: tbl-intro-outlier-features
# | tbl-cap: "Features contributing the most |z| > 3 values (raw scale)."
outlier_feature_summary.loc[:, ["pretty", "n_values_|z|>3"]].rename(
    columns={
        "pretty": "Feature",
        "n_values_|z|>3": "Count of |z| > 3 values",
    },
)
```

We therefore report both IQR- and Z‑based checks (Ch. 2) and stress that multivariate conclusions can shift when a small set of extreme countries dominates covariance structure.

## Research questions

1. Which predictors have the most significant explanatory power for cross‑country life expectancy in 2014?
2. What interactions and nonlinearities exist in the cross-sectional data?
3. How do parsimonious vs. richer linear models compare on train vs. 5‑fold CV error?
4. Do key assumptions (linearity, normality, homoscedasticity, independence, leverage) hold, and how should violations be addressed?
5. How sensitive are results to outlier handling (IQR vs. Z‑score) and to multicollinearity among correlated blocks (HDI vs. schooling; immunization rates)?

## Analytical flow

1. **Preprocessing:** header normalization, type conversion, year selection, transforms for skewed predictors, and z‑scoring of numeric predictors; documented missing‑value and outlier handling.
2. **Exploration:** correlation structure and grouped PCA to quantify redundancy and dominant dimensions.
3. **Modelling:** baseline univariate OLS, core multivariate OLS, assumption diagnostics, CV; grouped PCA + regression to mitigate multicollinearity.
4. **Interpretation:** effect sizes with uncertainty, practical relevance, and stated limitations.

## Roadmap

Preprocessing (Ch. 2) → PCA (Ch. 3) → Clustering (Ch. 4) → Regression (Ch. 5). Each chapter cites the generating notebook(s) for figures/tables to keep provenance explicit.
