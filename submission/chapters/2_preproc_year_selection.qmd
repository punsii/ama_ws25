---
title: "Year Selection"
format:
  html:
    toc: true
---

# Selecting a representative cross-sectional year

The dataset is a country-year panel; repeated observations per country can induce serial dependence in residuals and violate the regression assumption of no autocorrelation. We therefore conduct the main multivariate analyses on a single cross-section and select a representative year that balances recency, predictor missingness, and within-year typicality (Isolation Forest).


```{python}
# | label: setup-year-selection
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

from ama_tlbx.data import LECol, LifeExpectancyDataset
from ama_tlbx.utils.plotting_config import DEFAULT_PLOT_CFG
np.random.seed(42)

DEFAULT_PLOT_CFG.apply_global()

```

## Load the longitudinal panel

```{python}
# | label: load-longitudinal
le_ds = LifeExpectancyDataset.from_csv(
    aggregate_by_country=False,
    drop_missing_target=True,
    resolve_nand_pred=False,
)

df = le_ds.df

print(f"Total observations: {len(df):,}")
print(f"Countries: {df[LECol.COUNTRY].nunique()}")
print(f"Years: {df[LECol.YEAR].nunique()}")
print(
    f"Year range: {df[LECol.YEAR].dt.year.min():.0f} - {df[LECol.YEAR].dt.year.max():.0f}"
)

missing_target_by_year = (
    df.assign(year=lambda d: d[LECol.YEAR].dt.year)
    .groupby("year")[LECol.TARGET]
    .apply(lambda s: s.isna().sum())
    .rename("missing_target_n")
    .to_frame()
)
print(f"Missing target rows (all years): {int(missing_target_by_year.sum().iloc[0])}")
```


Since we drop ten outlier countries with a singular presence in 2013 and missing targets, the remaining panel provides full target coverage from 2000 to 2015 for 183 countries (2,988 observations). Year selection is therefore driven only by predictor missingness and within-year typicality.


## Predictor missingness by year

For each year $y$, we summarize the mean predictor missingness as $m_y$, defined as the percent of missing values across predictors columns.

```{python}
# | label: tbl-year-completeness
# | tbl-cap: "Predictor missingness by year (panel: 183 countries, 2000-2015)."
numeric_cols = le_ds.feature_columns(include_target=False)

year_stats = (
    df.groupby(LECol.YEAR)
    .agg(
        pred_missing_pct=(
            numeric_cols[0],
            lambda x: df.loc[x.index, numeric_cols].isna().mean().mean() * 100,
        ),
    )
    .reset_index()
    .sort_values(by="pred_missing_pct", ascending=True)
)
```


```{python}
# | label: fig-completeness-over-time
# | fig-cap: "Predictor missingness by year."
fig, ax = plt.subplots(1, 1, figsize=(12, 6))

year_stats_time = year_stats.sort_values(LECol.YEAR).assign(
    year=lambda d: d[LECol.YEAR].dt.year
)

sns.barplot(
    data=year_stats_time,
    x="year",
    y="pred_missing_pct",
    alpha=0.7,
    ax=ax,
    color="steelblue",
)
ax.set_xlabel("Year")
ax.set_ylabel("Predictor missingness (%)")
ax.set_title("Predictor Missingness by Year")
ax.tick_params(axis="x", rotation=45)

plt.tight_layout()
plt.show()
```

Predictor missingness declines from 2000 through the mid-2000s and then plateaus. The main outlier is **2015**, which shows a sharp predictor-missingness spike (13.32%). We therefore restrict candidates to **2007-2014** and exclude **2015** due to the missingness spike.

## Multivariate anomaly burden in candidate years

Predictor missingness alone does not guarantee typicality, so we estimate within-year anomaly rates using Isolation Forest on complete cases; the share of flagged countries summarizes within-year coherence (lower is more typical).

```{python}
# | label: fig-outliers-by-year
# | fig-cap: "Share of countries flagged as Isolation Forest anomalies (per year)."
candidate_years = list(range(2007, 2015))

feature_cols = le_ds.feature_columns(include_target=False)
outlier_rows: list[dict[str, float]] = []
for year in candidate_years:
    iso_result = (
        LifeExpectancyDataset(df=df[df[LECol.YEAR].dt.year == year].copy())
        .make_isolation_forest_outlier_detector(
            columns=feature_cols,
            standardized=True,
            random_state=42,
            n_estimators=100,
        )
        .fit()
        .result()
    )
    outlier_rate = iso_result.n_outliers_per_row.gt(0).mean()
    outlier_rows.append(
        {
            "year": year,
            "outlier_rate": outlier_rate,
            "mean_outliers": iso_result.n_outliers_per_row.mean(),
            "n_rows": float(len(iso_result.n_outliers_per_row)),
        }
    )

df_mean_outliers = (
    pd.DataFrame(outlier_rows)
    .assign(outlier_rate_pct=lambda d: d["outlier_rate"] * 100)
    .sort_values("outlier_rate")
)
sns.barplot(
    df_mean_outliers,
    x="year",
    y="outlier_rate_pct",
    hue="outlier_rate_pct",
    palette="coolwarm",
)
plt.ylabel("Countries flagged (%)")
plt.show()
```

## Combined quality score and final recommendation

To balance predictor missingness with anomaly burden, we invert both metrics to a 0--100 "quality" scale using their absolute percentages (lower is better). The combined score

$$
Q_y = 0.8\,M^{\star}_y + 0.2\,O^{\star}_y
$$

prioritizes low missingness while still penalizing years with unusually many outliers, where $M^{\star}_y$ is inverted missingness and $O^{\star}_y$ is inverted outlier rate.

```{python}
# | label: fig-combined-year-score
# | fig-cap: "Missingness quality, outlier quality, and the combined score."
comparison_df = (
    year_stats[year_stats[LECol.YEAR].dt.year.isin(candidate_years)]
    .assign(year=lambda d: d[LECol.YEAR].dt.year)[["year", "pred_missing_pct"]]
    .merge(
        df_mean_outliers.loc[:, ["year", "outlier_rate"]],
        on="year",
    )
    .assign(
        missingness_quality_norm=lambda d: 100 - d["pred_missing_pct"],
        outlier_quality_norm=lambda d: 100 - d["outlier_rate"] * 100,
        combined_score=lambda d: d["missingness_quality_norm"] * 0.8
        + d["outlier_quality_norm"] * 0.2,
    )
)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

sns.barplot(
    data=comparison_df.melt(
        id_vars="year",
        value_vars=["missingness_quality_norm", "outlier_quality_norm"],
        var_name="Metric",
        value_name="Score",
    ).replace(
        {
            "missingness_quality_norm": "Predictor missingness (inverted)",
            "outlier_quality_norm": "Outlier quality",
        }
    ),
    x="year",
    y="Score",
    hue="Metric",
    ax=ax1,
)
ax1.set(
    xlabel="Year",
    ylabel="Quality score (0--100)",
    title="Predictor missingness vs outlier quality",
)
ax1.legend(title=None)
ax1.grid(True, alpha=0.3, axis="y")

sns.barplot(
    data=comparison_df,
    x="year",
    y="combined_score",
    color="darkgreen",
    alpha=0.7,
    ax=ax2,
)

best_idx = comparison_df["combined_score"].idxmax()
score_top = comparison_df.loc[best_idx, "combined_score"]
best_year = (
    comparison_df[comparison_df["combined_score"] >= score_top]
    .sort_values("year")
    .iloc[-1]["year"]
)
best_row = comparison_df.query("year == @best_year").iloc[0]

ax2.set(
    xlabel="Year",
    ylabel="Combined score",
    title="Combined quality score\n(80% low missingness + 20% low outliers)",
)
ax2.grid(True, alpha=0.3, axis="y")
sns.despine(fig=fig)
plt.tight_layout()
plt.show()

print(f"\n{'=' * 70}\nFINAL YEAR RECOMMENDATION\n{'=' * 70}")
print(f"  Best year: {int(best_year)}")
print(f"   Combined score: {best_row['combined_score']:.1f}/100")
print(f"   Predictor missingness: {best_row['pred_missing_pct']:.2f}%")
print(f"   Outlier rate: {best_row['outlier_rate'] * 100:.2f}%")
print("=" * 70)
```

The combined score indicate minimal differences among candidate years because predictor missingness has plateaued and anomaly rates are tightly clustered. We therefore select the **most recent** year within one point of the maximum score, which yields **2014**.
