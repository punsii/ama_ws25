---
title: "Data Cleaning & Preprocessing"
format:
  html:
    toc: true
---

# Overview

This chapter documents the deterministic preprocessing workflow implemented in `ama-tlbx` for the WHO Life Expectancy dataset and clarifies which dataset views are used in downstream chapters. The raw data are a country-year panel (2000â€“2015); to reduce within-country temporal dependence, most multivariate analyses in this report use the 2014 cross-section (see [Year Selection](2_preproc_year_selection.qmd)). We elaborate on (i) deterministic cleaning and type conversion, (ii) missing-value handling (target vs predictors), and (iii) transformations and standardization.

## Preprocessing workflow (ama-tlbx)

::: {#fig-preproc-flow}
![](../figures/ama_preprocessing_flow.svg){width=100%}

Preprocessing flow in `ama-tlbx`.
:::

Figure @fig-preproc-flow summarizes the pipeline executed by `LifeExpectancyDataset.from_csv()`. After normalizing headers to stable snake_case names and converting types (`year` parsed; development status recoded), missingness in the outcome can be handled separately from missingness in predictors. The next decision is whether to aggregate the panel to one record per country (e.g., select 2014) or keep the full longitudinal data. Finally, predictors can either be left on their original scale, standardized, or transformed-and-standardized (`tf_only()` / `tf_and_norm()`), where the per-variable transformation rules are taken from the column metadata.

The workflow is driven by a schema-as-code layer: all variables are accessed via the `LECol` enum (with `ColumnMetadata`), which defines original names, dtypes, display labels, and default transformations. This makes preprocessing choices explicit and reproducible across chapters.

## Missing Values and analysis views

Missingness in the outcome (`life_expectancy`) is handled separately from missingness in predictors. In the raw panel, 10 of 2,938 country-year rows ($ \approx $ 0.34%) have missing life expectancy; these correspond to 10 countries that appear only once in the dataset. When `drop_missing_target=True`, these rows (and countries) are removed before any further processing.

Predictor missingness is controlled by `resolve_nand_pred`. Some analyses require a fully observed predictor matrix (e.g., PCA, standardized regression), while others can operate on partially observed predictors (e.g., univariate plots of the target). We therefore distinguish the raw 2014 cross-section from complete-case and imputed variants, and we report the effective sample size in each chapter.

## Dataset snapshots

```{python}
# | label: tbl-dataset-snapshots
# | tbl-cap: "Dataset snapshots under alternative missing-value strategies."
import pandas as pd

from ama_tlbx.data import LifeExpectancyDataset
from ama_tlbx.utils.plotting_config import DEFAULT_PLOT_CFG

DEFAULT_PLOT_CFG.apply_global()

snapshots = {
    "panel_raw": LifeExpectancyDataset.from_csv(
        aggregate_by_country=False,
        drop_missing_target=False,
        resolve_nand_pred=False,
    ).df,
    "xs_2014_raw": LifeExpectancyDataset.from_csv(
        aggregate_by_country=2014,
        drop_missing_target=False,
        resolve_nand_pred=False,
    ).df,
    "xs_2014_imputed": LifeExpectancyDataset.from_csv(
        aggregate_by_country=2014,
        drop_missing_target=True,
        resolve_nand_pred="carry_forward",
    ).df,
}


summary_rows = []
for name, df in snapshots.items():
    y_min, y_max = LifeExpectancyDataset.year_bounds(df)
    summary_rows.append(
        {
            "view": name,
            "rows": int(len(df)),
            "countries": LifeExpectancyDataset.country_count(df),
            "year_min": y_min,
            "year_max": y_max,
            "pct_missing_numeric": LifeExpectancyDataset.pct_missing_numeric(df),
        }
    )

(
    pd.DataFrame(summary_rows)
    .sort_values("view")
    .assign(pct_missing_numeric=lambda d: d.pct_missing_numeric.round(2))
    .style.hide(axis="index")
    .format({"pct_missing_numeric": "{:.2f}%"})
)
```

@tbl-dataset-snapshots highlights the trade-off between sample size and missing-value handling. In the raw panel, numeric predictors contain 4.36% missing entries; dropping missing targets removes 10 country-year rows and reduces country coverage from 193 to 183 because those countries occur only once. For the 2014 cross-section, life expectancy is observed for all 183 countries, but 2.81% of numeric predictor entries are missing. A complete-case strategy on predictors retains 131 countries (a loss of 52, $\approx$28%), whereas within-year mean imputation retains all 183 countries and yields a fully observed predictor matrix. For the longitudinal panel, the carry-forward strategy (within-country forward fill) retains fewer countries (133) but preserves more country-year observations than complete-case deletion, while global mean imputation maximizes coverage (183 countries, 2,928 country-years) at the cost of stronger assumptions about missingness.

## Transformations and standardization (`tf_only`, `tf_and_norm`)

```{python}
# | label: tbl-transforms
# | tbl-cap: "Per-column transforms applied before standardization"
import pandas as pd

from ama_tlbx.data.life_expectancy_columns import LifeExpectancyColumn as Col

rows = []
for col in Col:
    tf = col.transform
    tf_name = tf.__name__ if tf is not None else "none"
    rows.append(
        {
            "original": col.original_name,
            "column": col.value,
            "dtype": col.dtype_name,
            "pretty": col.pretty_name,
            "transform": tf_name,
        }
    )

transform_labels = {
    "_log1p_under_coverage": "log1p(100 - x)",
    "_status_dummies": "dummy (developed=1)",
    "log1p": "log1p(x)",
    "none": "none",
}

(
    pd.DataFrame(rows)
    .assign(
        column=lambda d: d["pretty"],
        transform=lambda d: d["transform"].map(transform_labels).fillna(d["transform"]),
    )
    .loc[:, ["column", "dtype", "transform"]]
    .sort_values("column")
    .reset_index(drop=True)
    .style.hide(axis="index")
)
```

Table @tbl-transforms documents the deterministic, per-variable transformations applied prior to standardization. Right-skewed, non-negative intensity variables (e.g., GDP, deaths, measles) are transformed using $\log(1+x)$ to reduce leverage from extreme values and to make linear relationships closer to homoscedastic in downstream models. Immunization variables are recorded as coverage percentages; we re-parameterize them as a shortfall $(100-x)$ and apply $\log(1+(100-x))$, so that larger values consistently represent worse coverage while preserving rank order (monotone transform). After transformation, numeric predictors are z-scored to place them on a comparable scale for PCA, clustering, and standardized regression; Pearson correlation is invariant to affine rescaling, so any changes in correlations after preprocessing arise from the nonlinear transforms rather than the z-scoring step. The target (life expectancy, years) remains in its original units. If residual missing values remain, `tf_and_norm()` median-fills numeric predictors only to avoid failures in standardization (this is separate from the explicit imputation choices in Table @tbl-dataset-snapshots).

To make the effect of standardization explicit, Table @tbl-standardization-summary reports per-feature means and standard deviations before and after z-scoring on the 2014 cross-section (predictors mean-imputed within the year; target excluded).

```{python}
# | label: tbl-standardization-summary
# | tbl-cap: "Predictor summary statistics before vs after z-scoring (2014 cross-section; mean-imputed predictors; target excluded)."
import pandas as pd

from ama_tlbx.data import LECol, LifeExpectancyDataset

le_xs_2014 = LifeExpectancyDataset.from_csv(
    aggregate_by_country=2014,
    resolve_nand_pred="carry_forward",
)
ds_predictors = LifeExpectancyDataset(
    df=le_xs_2014.df.drop(columns=[LECol.TARGET]),
)

raw = ds_predictors.df.loc[:, ds_predictors.numeric_cols]
z = ds_predictors.df_standardized.loc[:, ds_predictors.numeric_cols]

summary = (
    pd.DataFrame(
        {
            "mean_raw": raw.mean(),
            "sd_raw": raw.std(ddof=0),
            "mean_z": z.mean(),
            "sd_z": z.std(ddof=0),
        }
    )
    .assign(feature=lambda d: d.index.map(ds_predictors.get_pretty_name))
    .loc[:, ["feature", "mean_raw", "sd_raw", "mean_z", "sd_z"]]
    .rename(
        columns={
            "feature": "Feature",
            "mean_raw": "Mean (raw)",
            "sd_raw": "SD (raw)",
            "mean_z": "Mean (z)",
            "sd_z": "SD (z)",
        }
    )
    .sort_values("Feature")
    .reset_index(drop=True)
)

(
    summary.style.hide(axis="index").format(
        {
            "Mean (raw)": "{:,.2f}",
            "SD (raw)": "{:,.2f}",
            "Mean (z)": "{:.3f}",
            "SD (z)": "{:.3f}",
        }
    )
)
```

Figure @fig-standardization-comparison illustrates why standardization is required for scale-sensitive multivariate methods: on the raw scale, variables measured in large units dominate dispersion, whereas z-scoring places predictors on a comparable scale. For clarity, we exclude the target from this plot.

```{python}
# | label: fig-standardization-comparison
# | fig-cap: "Predictor scale before vs after z-scoring (2014 cross-section; mean-imputed predictors; target excluded)."

ds_predictors.plot_standardization_comparison(figsize=(20, 10)).show()
```

Correlation and outlier diagnostics are in `3_correlation.qmd` and `2_outlier_detection.qmd`, respectively.
